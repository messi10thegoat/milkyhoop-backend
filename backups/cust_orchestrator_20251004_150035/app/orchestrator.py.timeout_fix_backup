"""
SuperIntelligent Customer Service Orchestrator - Production Implementation
Uses gRPC clients for all intelligence operations (NO cross-container imports)
"""
import asyncio
import logging
import time
import redis
import os
import hashlib
from typing import Dict, Any, Optional, List
import grpc
from app.clients.tenant_parser_client import TenantParserClient
from app.clients.ragcrud_client import RAGCRUDClient
from app.clients.ragllm_client import RAGLLMClient

logger = logging.getLogger(__name__)


class SuperIntelligentCustomerOrchestrator:
    """
    Production SuperIntelligent Customer Orchestrator
    
    Features:
    - 4-Tier SuperIntelligent confidence system via gRPC
    - Cost-optimized API routing 
    - Redis-based caching and cost tracking
    - Production-ready error handling
    - Complete orchestration pipeline
    """
    
    def __init__(self):
        """Initialize SuperIntelligent orchestrator with gRPC clients"""
        try:
            # Initialize gRPC service clients (NO local engine imports)
            self.tenant_parser = TenantParserClient()
            self.ragcrud = RAGCRUDClient()
            self.ragllm = RAGLLMClient()
            
            logger.info("gRPC clients initialized: tenant_parser, ragcrud, ragllm")
            
            # Initialize Redis for caching and cost tracking
            self.redis_client = self._initialize_redis()
            
            # Configuration (aligned with SuperIntelligent thresholds)
            self.tier_1_threshold = 0.85    # Direct FAQ (no API cost)
            self.tier_2_threshold = 0.60    # GPT Synthesis (medium cost)
            self.tier_3_threshold = 0.30    # Deep Understanding (high cost)
            # Below 0.30 = Tier 4 (Polite deflection, no cost)
            
            self.daily_budget_limit = 100000  # Rp 100k per tenant per day
            self.cache_ttl = 3600  # 1 hour cache
            self.max_processing_time = 15.0  # seconds
            
            logger.info("SuperIntelligentCustomerOrchestrator: FULLY OPERATIONAL (gRPC-based)")
            
        except Exception as e:
            logger.error(f"Failed to initialize SuperIntelligentCustomerOrchestrator: {str(e)}")
            raise
    
    def _initialize_redis(self):
        """Initialize Redis with production settings"""
        try:
            redis_client = redis.Redis(
                host=os.getenv('REDIS_HOST', 'milkyhoop-dev-redis-1'),
                port=int(os.getenv('REDIS_PORT', '6379')),
                password=os.getenv('REDIS_PASSWORD', ''),
                decode_responses=True,
                socket_timeout=5,
                socket_connect_timeout=5
            )
            redis_client.ping()
            logger.info("Redis connection: ESTABLISHED")
            return redis_client
        except Exception as e:
            logger.warning(f"Redis unavailable: {e}. Using in-memory fallback.")
            return None
    
    async def process_customer_query(
        self, 
        query: str, 
        tenant_id: str, 
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        SuperIntelligent Customer Query Processing via gRPC
        
        Flow:
        1. Cache check (if Redis available)
        2. FAQ retrieval via RAG CRUD
        3. Confidence calculation via Tenant Parser gRPC
        4. Decision making via Tenant Parser gRPC
        5. Response generation based on tier
        6. Cost tracking and caching
        """
        start_time = time.time()
        trace_id = session_id or f"trace_{int(time.time())}"
        
        try:
            logger.info(f"[{trace_id}] Processing: '{query[:50]}...' for {tenant_id}")
            
            # Step 1: Check cache first
            cached_response = await self._get_cached_response(tenant_id, query)
            if cached_response:
                logger.info(f"[{trace_id}] Cache HIT - returning cached response")
                return cached_response
            
            # Step 2: Check daily budget
            if await self._is_budget_exceeded(tenant_id):
                logger.warning(f"[{trace_id}] Daily budget exceeded for {tenant_id}")
                return self._create_budget_exceeded_response(tenant_id, session_id)
            
            # Step 3: FAQ Knowledge Retrieval
            faq_results = await self._retrieve_faq_knowledge(query, tenant_id, trace_id)
            
            # Step 4: Calculate Confidence via Tenant Parser gRPC
            confidence_data = await self.tenant_parser.calculate_confidence(
                query=query,
                tenant_id=tenant_id,
                faq_results=faq_results
            )
            confidence = confidence_data.get("confidence", 0.0)
            
            # Step 5: Get Decision via Tenant Parser gRPC
            decision = await self.tenant_parser.make_decision(
                confidence=confidence,
                tenant_id=tenant_id
            )
            
            logger.info(f"[{trace_id}] Decision: TIER {decision['tier']} - {decision['route']}")
            logger.info(f"[{trace_id}] Confidence: {confidence:.3f}, Cost: Rp {decision['cost_per_query']}")
            
            # Step 6: Execute tier-based routing
            response_data = await self._execute_tier_routing(
                decision, query, tenant_id, trace_id, faq_results, confidence
            )
            
            # Step 7: Track costs and cache
            await self._track_costs(tenant_id, decision['cost_per_query'])
            await self._cache_response(tenant_id, query, response_data)
            
            # Step 8: Assemble final response
            processing_time = (time.time() - start_time) * 1000
            
            result = {
                "status": "success",
                "response": response_data["response"],
                "tenant_id": tenant_id,
                "session_id": session_id,
                "trace_id": trace_id,
                "intent": "customer_inquiry",
                "confidence": confidence,
                "tier": decision["tier"],
                "route": decision["route"],
                "superintelligent_metadata": {
                    "confidence": confidence,
                    "tier": decision["tier"],
                    "route": decision["route"],
                    "api_call_made": decision["api_call"],
                    "cost_rp": decision["cost_per_query"],
                    "intelligence_level": decision["intelligence_level"],
                    "processing_time_ms": round(processing_time, 2),
                    "faq_count_used": decision["faq_count"],
                    "model_used": decision.get("model", "none")
                }
            }
            
            logger.info(f"[{trace_id}] Processing complete: {processing_time:.1f}ms")
            return result
            
        except Exception as e:
            logger.error(f"[{trace_id}] Processing error: {str(e)}")
            return self._create_error_response(str(e), tenant_id, session_id, time.time() - start_time)
    
    async def _retrieve_faq_knowledge(self, query: str, tenant_id: str, trace_id: str) -> List:
        """Retrieve FAQ knowledge with timeout and error handling"""
        try:
            faq_result = await asyncio.wait_for(
                self.ragcrud.search_faq(query, tenant_id, intent="customer_inquiry"),
                timeout=4.0
            )
            
            if isinstance(faq_result, dict) and 'results' in faq_result:
                return faq_result['results']
            elif isinstance(faq_result, list):
                return faq_result
            else:
                return []
                
        except asyncio.TimeoutError:
            logger.warning(f"[{trace_id}] FAQ retrieval timeout")
            return []
        except Exception as e:
            logger.error(f"[{trace_id}] FAQ retrieval error: {e}")
            return []
    
    async def _execute_tier_routing(
        self, 
        decision: Dict, 
        query: str, 
        tenant_id: str, 
        trace_id: str, 
        faq_results: List,
        confidence: float
    ) -> Dict[str, Any]:
        """Execute routing based on tier decision"""
        
        route = decision.get("route", "polite_deflection")
        
        if route == "direct_faq_fallback":
            # TIER 1: Direct FAQ Response via gRPC
            if faq_results and len(faq_results) > 0:
                response = await self.tenant_parser.extract_faq_answer(
                    faq_content=faq_results[0]['content'] if isinstance(faq_results[0], dict) else faq_results[0].content,
                    tenant_id=tenant_id
                )
                logger.info(f"[{trace_id}] TIER 1: Direct FAQ (Cost: Rp 0)")
            else:
                response = f"Maaf, informasi untuk {tenant_id} sedang tidak tersedia."
            
            return {
                "response": response,
                "response_type": "direct_faq",
                "api_cost": 0.0
            }
        
        elif route == "gpt_synthesis" or route == "deep_understanding":
            # TIER 2 & 3: LLM synthesis via gRPC
            try:
                intelligence_level = "synthesis" if route == "gpt_synthesis" else "deep"
                
                response = await asyncio.wait_for(
                    self.ragllm.generate_response(
                        query=query,
                        faq_context=faq_results,
                        intelligence_level=intelligence_level,
                        tenant_id=tenant_id,
                        model=decision.get("model")
                    ),
                    timeout=8.0
                )
                
                tier_num = 2 if route == "gpt_synthesis" else 3
                logger.info(f"[{trace_id}] TIER {tier_num}: LLM synthesis (Cost: Rp {decision['cost_per_query']})")
                
                return {
                    "response": response,
                    "response_type": f"llm_{intelligence_level}",
                    "api_cost": decision['cost_per_query']
                }
                
            except asyncio.TimeoutError:
                logger.warning(f"[{trace_id}] LLM timeout, fallback to FAQ")
                if faq_results:
                    response = await self.tenant_parser.extract_faq_answer(
                        faq_content=faq_results[0]['content'] if isinstance(faq_results[0], dict) else faq_results[0].content,
                        tenant_id=tenant_id
                    )
                else:
                    response = "Maaf, saya membutuhkan waktu lebih lama. Bisa coba lagi?"
                
                return {
                    "response": response,
                    "response_type": "timeout_fallback",
                    "api_cost": 0.0
                }
            
            except Exception as e:
                logger.error(f"[{trace_id}] LLM error: {e}")
                if faq_results:
                    response = await self.tenant_parser.extract_faq_answer(
                        faq_content=faq_results[0]['content'] if isinstance(faq_results[0], dict) else faq_results[0].content,
                        tenant_id=tenant_id
                    )
                else:
                    response = "Maaf, saya mengalami kendala teknis. Silakan coba lagi."
                
                return {
                    "response": response,
                    "response_type": "error_fallback", 
                    "api_cost": 0.0
                }
        
        else:
            # TIER 4: Polite Deflection via gRPC
            response = await self.tenant_parser.get_polite_deflection(
                tenant_id=tenant_id,
                context=query
            )
            logger.info(f"[{trace_id}] TIER 4: Polite deflection (Cost: Rp 0)")
            
            return {
                "response": response,
                "response_type": "polite_deflection",
                "api_cost": 0.0
            }
    
    def _get_cache_key(self, tenant_id: str, query: str) -> str:
        """Generate cache key for query"""
        query_hash = hashlib.md5(query.lower().encode()).hexdigest()[:8]
        return f"cache:{tenant_id}:{query_hash}"
    
    async def _get_cached_response(self, tenant_id: str, query: str) -> Optional[Dict]:
        """Get cached response if available"""
        if not self.redis_client:
            return None
        
        try:
            cache_key = self._get_cache_key(tenant_id, query)
            cached = self.redis_client.get(cache_key)
            
            if cached:
                import json
                return json.loads(cached)
                
        except Exception as e:
            logger.warning(f"Cache retrieval error: {e}")
        
        return None
    
    async def _cache_response(self, tenant_id: str, query: str, response_data: Dict):
        """Cache response for future use"""
        if not self.redis_client:
            return
        
        try:
            cache_key = self._get_cache_key(tenant_id, query)
            import json
            self.redis_client.setex(cache_key, self.cache_ttl, json.dumps(response_data))
            
        except Exception as e:
            logger.warning(f"Cache storage error: {e}")
    
    async def _track_costs(self, tenant_id: str, cost: float):
        """Track daily costs per tenant"""
        if cost == 0.0:
            return
        
        if self.redis_client:
            try:
                cost_key = f"daily_cost:{tenant_id}"
                self.redis_client.incrbyfloat(cost_key, cost)
                
                # Set expiry to end of day
                import datetime
                tomorrow = datetime.datetime.now() + datetime.timedelta(days=1)
                midnight = tomorrow.replace(hour=0, minute=0, second=0, microsecond=0)
                expire_seconds = int((midnight - datetime.datetime.now()).total_seconds())
                self.redis_client.expire(cost_key, expire_seconds)
                
            except Exception as e:
                logger.warning(f"Cost tracking error: {e}")
    
    async def _is_budget_exceeded(self, tenant_id: str) -> bool:
        """Check if daily budget is exceeded"""
        if self.redis_client:
            try:
                cost_key = f"daily_cost:{tenant_id}"
                current_cost = float(self.redis_client.get(cost_key) or 0)
                return current_cost > self.daily_budget_limit
            except:
                return False
        return False
    
    def _create_budget_exceeded_response(self, tenant_id: str, session_id: str) -> Dict[str, Any]:
        """Create response when daily budget is exceeded"""
        return {
            "status": "success",
            "response": f"Maaf, layanan {tenant_id} telah mencapai batas penggunaan harian. Silakan coba lagi besok.",
            "tenant_id": tenant_id,
            "session_id": session_id,
            "confidence": 0.0,
            "tier": 4,
            "route": "budget_exceeded",
            "superintelligent_metadata": {
                "tier": 4,
                "route": "budget_exceeded",
                "cost_rp": 0.0,
                "intelligence_level": "budget_protection"
            }
        }
    
    def _create_error_response(
        self, 
        error_msg: str, 
        tenant_id: str, 
        session_id: str, 
        processing_time: float
    ) -> Dict[str, Any]:
        """Create standardized error response"""
        return {
            "status": "error",
            "response": "Maaf, saya mengalami kendala teknis. Silakan coba lagi dalam beberapa saat.",
            "tenant_id": tenant_id,
            "session_id": session_id,
            "confidence": 0.0,
            "tier": 4,
            "route": "system_error",
            "superintelligent_metadata": {
                "tier": 4,
                "route": "system_error",
                "cost_rp": 0.0,
                "processing_time_ms": round(processing_time * 1000, 2),
                "error_details": error_msg
            }
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """Comprehensive health check"""
        try:
            health_results = {}
            
            # Check Tenant Parser
            health_results["tenant_parser"] = "healthy" if await self.tenant_parser.health_check() else "unhealthy"
            
            # Check RAG CRUD
            try:
                await asyncio.wait_for(self.ragcrud.search_faq("test", "test"), timeout=1.0)
                health_results["ragcrud"] = "healthy"
            except:
                health_results["ragcrud"] = "unhealthy"
            
            # Check RAG LLM
            health_results["ragllm"] = "healthy" if await self.ragllm.health_check() else "unhealthy"
            
            # Check Redis
            if self.redis_client:
                try:
                    self.redis_client.ping()
                    health_results["redis_cache"] = "healthy"
                except:
                    health_results["redis_cache"] = "unhealthy"
            else:
                health_results["redis_cache"] = "unavailable (using fallback)"
            
            # Overall status
            critical_services = ["tenant_parser", "ragcrud"]
            critical_healthy = all(
                "healthy" in health_results.get(service, "") 
                for service in critical_services
            )
            
            return {
                "status": "healthy" if critical_healthy else "degraded",
                "services": health_results,
                "architecture": "gRPC_distributed",
                "superintelligent_features": [
                    "4_tier_confidence_system",
                    "cost_optimization",
                    "redis_caching",
                    "budget_tracking", 
                    "intelligent_routing"
                ],
                "version": "4.0.1-grpc-fixed",
                "orchestrator": "SuperIntelligentCustomerOrchestrator"
            }
            
        except Exception as e:
            logger.error(f"Health check failed: {str(e)}")
            return {
                "status": "unhealthy",
                "error": str(e),
                "orchestrator": "SuperIntelligentCustomerOrchestrator"
            }