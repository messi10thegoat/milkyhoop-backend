from backend.api_gateway.libs.milkyhoop_prisma import Prisma
import asyncio
import signal
import logging
import os
import json
import time
import redis.asyncio as redis
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from functools import wraps
import grpc
from grpc import aio
from grpc_health.v1 import health, health_pb2, health_pb2_grpc

# Import generated stubs
from app import cust_context_pb2_grpc as pb_grpc
from app import cust_context_pb2 as pb

# Import our services
from app.services.context_manager import CustomerContextManager
from app.services.entity_extractor import CustomerEntityExtractor
from app.models.conversation import ConversationContext, ConversationEntity
from app.config import settings

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)
logger = logging.getLogger("CustContextLevel13")

# ========== CONFIGURATION SETTINGS ==========

class Settings:
    """Centralized configuration settings"""
    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")
    GRPC_PORT = int(os.getenv("GRPC_PORT", "5008"))
    
    # TTL Settings (configurable via environment)
    REDIS_CACHE_TTL = int(os.getenv("REDIS_CACHE_TTL", "300"))  # 5 minutes
    HISTORY_TTL = int(os.getenv("HISTORY_TTL", "3600"))  # 1 hour
    CONFIG_CACHE_TTL = int(os.getenv("CONFIG_CACHE_TTL", "300"))  # 5 minutes
    
    # Limits
    MAX_HISTORY_TURNS = int(os.getenv("MAX_HISTORY_TURNS", "20"))
    MAX_MEMORY_SESSIONS = int(os.getenv("MAX_MEMORY_SESSIONS", "1000"))
    MAX_LATENCY_SAMPLES = int(os.getenv("MAX_LATENCY_SAMPLES", "100"))

settings = Settings()

# ========== TENANT CONFIGURATION SYSTEM ==========

@dataclass
class TenantConfig:
    """Tenant-specific configuration for conversation intelligence"""
    tenant_id: str
    language: str = "id"
    mood_patterns: Dict[str, List[str]] = None
    intent_patterns: Dict[str, List[str]] = None
    product_patterns: Dict[str, List[str]] = None
    frustration_indicators: List[str] = None
    response_style: str = "friendly_professional"
    max_history_turns: int = 20
    conversation_ttl: int = 3600
    
    def __post_init__(self):
        """Initialize default patterns if not provided"""
        if self.mood_patterns is None:
            self.mood_patterns = DEFAULT_MOOD_PATTERNS
        if self.intent_patterns is None:
            self.intent_patterns = DEFAULT_INTENT_PATTERNS
        if self.product_patterns is None:
            self.product_patterns = DEFAULT_PRODUCT_PATTERNS
        if self.frustration_indicators is None:
            self.frustration_indicators = DEFAULT_FRUSTRATION_INDICATORS

# Default patterns (fallback for all tenants)
DEFAULT_MOOD_PATTERNS = {
    'happy': ['senang', 'gembira', 'suka', 'bagus', 'mantap', 'oke', 'terima kasih', 'makasih'],
    'frustrated': ['kesal', 'bingung', 'susah', 'ribet', 'lama', 'lambat', 'error', 'gagal', 'tidak bisa'],
    'curious': ['bagaimana', 'gimana', 'apa itu', 'kenapa', 'mengapa', 'bisa tidak', 'bisakah'],
    'urgent': ['segera', 'cepat', 'urgent', 'penting', 'butuh sekarang', 'tolong'],
    'confused': ['bingung', 'tidak mengerti', 'tidak paham', 'maksudnya', 'apa maksudnya']
}

DEFAULT_INTENT_PATTERNS = {
    'browsing': ['lihat', 'cek', 'info', 'tanya', 'apa ada'],
    'comparing': ['bandingkan', 'beda', 'mana yang', 'lebih baik', 'vs'],
    'buying': ['beli', 'order', 'pesan', 'checkout', 'bayar', 'harga'],
    'support': ['help', 'bantuan', 'masalah', 'error', 'tidak bisa', 'trouble']
}

DEFAULT_PRODUCT_PATTERNS = {
    'clothing': ['baju', 'kemeja', 'kaos', 'celana', 'dress', 'jaket'],
    'electronics': ['hp', 'laptop', 'komputer', 'gadget', 'elektronik'],
    'services': ['konsultasi', 'konseling', 'terapi', 'layanan', 'jasa']
}

DEFAULT_FRUSTRATION_INDICATORS = [
    'tidak bisa', 'gagal', 'error', 'bermasalah', 'ribet', 'susah', 
    'lama', 'lambat', 'tidak jelas', 'bingung terus'
]

class TenantConfigManager:
    """Thread-safe tenant configuration manager with Redis caching"""
    
    def __init__(self):
        self.redis_client = None
        self.config_cache = {}
        self._cache_lock = asyncio.Lock()  # Thread-safe cache access
    
    async def initialize(self):
        """Initialize Redis connection"""
        try:
            self.redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True)
            await self.redis_client.ping()
            logger.info("üîß TenantConfigManager initialized with Redis")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis not available, using memory cache: {e}")
            self.redis_client = None
    
    async def close(self):
        """Cleanup Redis connection"""
        if self.redis_client:
            try:
                await self.redis_client.close()
                logger.info("üîå Redis connection closed")
            except Exception as e:
                logger.warning(f"Error closing Redis: {e}")
    
    def _memory_key(self, tenant_id: str, *suffix) -> str:
        """Generate consistent memory keys"""
        parts = [tenant_id] + list(suffix)
        return ":".join(parts)
    
    async def get_tenant_config(self, tenant_id: str) -> TenantConfig:
        """Thread-safe tenant configuration retrieval with caching"""
        cache_key = f"tenant_config:{tenant_id}"
        
        # Thread-safe cache access
        async with self._cache_lock:
            # Try memory cache first
            if cache_key in self.config_cache:
                cached_time, config = self.config_cache[cache_key]
                if time.time() - cached_time < settings.CONFIG_CACHE_TTL:
                    return config
        
        # Try Redis if available
        if self.redis_client:
            try:
                cached_data = await self.redis_client.get(cache_key)
                if cached_data:
                    config_dict = json.loads(cached_data)
                    config = TenantConfig(**config_dict)
                    
                    # Update memory cache (thread-safe)
                    async with self._cache_lock:
                        self.config_cache[cache_key] = (time.time(), config)
                    return config
            except Exception as e:
                logger.warning(f"Redis cache miss for {tenant_id}: {e}")
        
        # Fallback to default config
        config = TenantConfig(tenant_id=tenant_id)
        
        # Cache the result (thread-safe)
        async with self._cache_lock:
            self.config_cache[cache_key] = (time.time(), config)
        
        if self.redis_client:
            try:
                await self.redis_client.setex(
                    cache_key, 
                    settings.CONFIG_CACHE_TTL, 
                    json.dumps(asdict(config))
                )
            except Exception as e:
                logger.warning(f"Failed to cache config: {e}")
        
        return config

# ========== CONVERSATION HISTORY MANAGER ==========

class ConversationHistoryManager:
    """Thread-safe conversation history with Redis backend and bulk operations"""
    
    def __init__(self):
        self.redis_client = None
        self.memory_fallback = {}
        self._memory_lock = asyncio.Lock()  # Thread-safe memory access
    
    async def initialize(self):
        """Initialize Redis connection"""
        try:
            self.redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True)
            await self.redis_client.ping()
            logger.info("üíæ ConversationHistoryManager initialized with Redis")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Redis not available, using memory fallback: {e}")
            self.redis_client = None
    
    async def close(self):
        """Cleanup Redis connection"""
        if self.redis_client:
            try:
                await self.redis_client.close()
                logger.info("üîå History Redis connection closed")
            except Exception as e:
                logger.warning(f"Error closing history Redis: {e}")
    
    def _history_key(self, tenant_id: str, session_id: str) -> str:
        """Generate consistent history keys"""
        return f"history:{tenant_id}:{session_id}"
    
    async def get_history(self, tenant_id: str, session_id: str) -> List[str]:
        """Thread-safe conversation history retrieval"""
        key = self._history_key(tenant_id, session_id)
        
        if self.redis_client:
            try:
                messages = await self.redis_client.lrange(key, 0, -1)
                return messages or []
            except Exception as e:
                logger.warning(f"Redis get_history failed: {e}")
        
        # Thread-safe memory fallback
        async with self._memory_lock:
            return self.memory_fallback.get(key, [])
    
    async def add_message(self, tenant_id: str, session_id: str, message: str, max_turns: Optional[int] = None) -> None:
        """Thread-safe message addition with bulk Redis operations"""
        if max_turns is None:
            max_turns = settings.MAX_HISTORY_TURNS
            
        key = self._history_key(tenant_id, session_id)
        
        if self.redis_client:
            try:
                # Use Redis pipeline for bulk operations
                pipe = self.redis_client.pipeline()
                pipe.lpush(key, message)
                pipe.ltrim(key, 0, max_turns - 1)
                pipe.expire(key, settings.HISTORY_TTL)
                await pipe.execute()
                return
            except Exception as e:
                logger.warning(f"Redis add_message failed: {e}")
        
        # Thread-safe memory fallback
        async with self._memory_lock:
            if key not in self.memory_fallback:
                self.memory_fallback[key] = []
            
            self.memory_fallback[key].insert(0, message)
            if len(self.memory_fallback[key]) > max_turns:
                self.memory_fallback[key] = self.memory_fallback[key][:max_turns]
            
            # Prevent memory bloat
            if len(self.memory_fallback) > settings.MAX_MEMORY_SESSIONS:
                oldest_keys = list(self.memory_fallback.keys())[:100]
                for old_key in oldest_keys:
                    del self.memory_fallback[old_key]
    
    async def clear_history(self, tenant_id: str, session_id: str) -> None:
        """Thread-safe conversation history cleanup"""
        key = self._history_key(tenant_id, session_id)
        
        if self.redis_client:
            try:
                await self.redis_client.delete(key)
            except Exception as e:
                logger.warning(f"Redis clear_history failed: {e}")
        
        async with self._memory_lock:
            if key in self.memory_fallback:
                del self.memory_fallback[key]

# ========== TELEMETRY & METRICS ==========

class MetricsCollector:
    """Enhanced metrics collection with error classification"""
    
    # Error classification
    NETWORK_ERRORS = (ConnectionError, TimeoutError, redis.RedisError)
    LOGIC_ERRORS = (ValueError, KeyError, TypeError, AttributeError)
    
    def __init__(self):
        self.method_calls = {}
        self.method_latencies = {}
        self.error_counts = {}
        self._metrics_lock = asyncio.Lock()  # Thread-safe metrics
    
    async def record_call(self, method_name: str, latency: float, success: bool, error: Optional[Exception] = None) -> None:
        """Thread-safe method call recording with error classification"""
        async with self._metrics_lock:
            # Call counts
            if method_name not in self.method_calls:
                self.method_calls[method_name] = {"success": 0, "network_error": 0, "logic_error": 0, "unknown_error": 0}
            
            if success:
                self.method_calls[method_name]["success"] += 1
            else:
                # Classify error type
                if error and isinstance(error, self.NETWORK_ERRORS):
                    self.method_calls[method_name]["network_error"] += 1
                elif error and isinstance(error, self.LOGIC_ERRORS):
                    self.method_calls[method_name]["logic_error"] += 1
                else:
                    self.method_calls[method_name]["unknown_error"] += 1
            
            # Latencies (bounded list)
            if method_name not in self.method_latencies:
                self.method_latencies[method_name] = []
            
            self.method_latencies[method_name].append(latency)
            # Keep only last N measurements
            if len(self.method_latencies[method_name]) > settings.MAX_LATENCY_SAMPLES:
                self.method_latencies[method_name] = self.method_latencies[method_name][-settings.MAX_LATENCY_SAMPLES:]
    
    async def get_stats(self) -> Dict[str, Any]:
        """Thread-safe metrics statistics"""
        async with self._metrics_lock:
            stats = {}
            for method, calls in self.method_calls.items():
                latencies = self.method_latencies.get(method, [])
                stats[method] = {
                    "calls": calls,
                    "avg_latency": sum(latencies) / len(latencies) if latencies else 0,
                    "max_latency": max(latencies) if latencies else 0,
                    "min_latency": min(latencies) if latencies else 0,
                    "p95_latency": sorted(latencies)[int(len(latencies) * 0.95)] if latencies else 0
                }
            return stats

def telemetry(metrics_collector: MetricsCollector):
    """Enhanced decorator with error classification"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            method_name = func.__name__
            success = True
            error = None
            
            try:
                result = await func(*args, **kwargs)
                return result
            except Exception as e:
                success = False
                error = e
                logger.error(f"Method {method_name} failed: {e}")
                raise
            finally:
                latency = time.time() - start_time
                await metrics_collector.record_call(method_name, latency, success, error)
                logger.debug(f"üìä {method_name}: {latency:.3f}s ({'‚úÖ' if success else '‚ùå'})")
        
        return wrapper
    return decorator

# ========== ENHANCED CONVERSATION INTELLIGENCE ==========

class ConversationIntelligence:
    """Enhanced conversation intelligence with tenant-specific patterns"""
    
    def __init__(self, config_manager: TenantConfigManager):
        self.config_manager = config_manager
    
    async def detect_mood(self, text: str, tenant_id: str) -> Tuple[str, float, str]:
        """Detect user mood with tenant-specific patterns"""
        config = await self.config_manager.get_tenant_config(tenant_id)
        text_lower = text.lower()
        mood_scores = {}
        
        for mood, patterns in config.mood_patterns.items():
            score = sum(1 for pattern in patterns if pattern in text_lower)
            if score > 0:
                mood_scores[mood] = score / len(patterns)
        
        if not mood_scores:
            return 'neutral', 0.5, 'No clear mood indicators found'
        
        detected_mood = max(mood_scores, key=mood_scores.get)
        confidence = mood_scores[detected_mood]
        reason = f"Detected patterns matching {detected_mood} mood"
        
        return detected_mood, confidence, reason
    
    async def track_intent_progression(self, text: str, previous_intents: List[str], tenant_id: str) -> Tuple[str, float, str]:
        """Track user intent with tenant-specific patterns"""
        config = await self.config_manager.get_tenant_config(tenant_id)
        text_lower = text.lower()
        intent_scores = {}
        
        for intent, patterns in config.intent_patterns.items():
            score = sum(1 for pattern in patterns if pattern in text_lower)
            if score > 0:
                intent_scores[intent] = score / len(patterns)
        
        if not intent_scores:
            current_intent = 'general_inquiry'
            confidence = 0.3
        else:
            current_intent = max(intent_scores, key=intent_scores.get)
            confidence = intent_scores[current_intent]
        
        # Recommend response style based on intent progression
        if len(previous_intents) > 0 and previous_intents[-1] == 'browsing' and current_intent == 'buying':
            response_style = 'conversion_focused'
        elif current_intent == 'support':
            response_style = 'problem_solving'
        elif current_intent == 'comparing':
            response_style = 'informative_detailed'
        else:
            response_style = config.response_style
        
        return current_intent, confidence, response_style
    
    async def detect_products_mentioned(self, text: str, tenant_id: str) -> Dict[str, Any]:
        """Detect products with tenant-specific patterns"""
        config = await self.config_manager.get_tenant_config(tenant_id)
        text_lower = text.lower()
        detected_products = []
        categories = []
        confidences = []
        
        for category, patterns in config.product_patterns.items():
            for pattern in patterns:
                if pattern in text_lower:
                    detected_products.append(pattern)
                    categories.append(category)
                    confidences.append(0.8)
        
        return {
            'products': detected_products,
            'categories': list(set(categories)),
            'confidences': confidences
        }
    
    async def detect_frustration_level(self, text: str, conversation_history: List[str], tenant_id: str) -> Dict[str, Any]:
        """Detect frustration with tenant-specific indicators"""
        config = await self.config_manager.get_tenant_config(tenant_id)
        text_lower = text.lower()
        
        frustration_count = sum(1 for indicator in config.frustration_indicators 
                               if indicator in text_lower)
        
        # Check for repeated issues in history
        history_frustration = sum(1 for msg in conversation_history[-3:] 
                                 for indicator in config.frustration_indicators 
                                 if indicator in msg.lower())
        
        total_score = frustration_count + (history_frustration * 0.5)
        
        if total_score >= 3:
            level = 'high'
            actions = ['escalate_to_human', 'offer_direct_help', 'apologize_proactively']
        elif total_score >= 1.5:
            level = 'medium'
            actions = ['provide_clearer_explanation', 'offer_alternative_solution']
        else:
            level = 'low'
            actions = ['continue_normal_flow']
        
        return {
            'level': level,
            'score': total_score,
            'indicators': [ind for ind in config.frustration_indicators if ind in text_lower],
            'recommended_actions': actions
        }

# ========== MAIN SERVICE IMPLEMENTATION ==========

class CustContextServicer(pb_grpc.CustContextServiceServicer):
    """Production-Grade Level 13 Customer Context Service"""
    
    def __init__(self):
        self.context_manager = CustomerContextManager()
        self.entity_extractor = CustomerEntityExtractor()
        
        # Initialize managers
        self.config_manager = TenantConfigManager()
        self.history_manager = ConversationHistoryManager()
        self.metrics = MetricsCollector()
        self.intelligence = ConversationIntelligence(self.config_manager)
        
        # Internal state (Redis-backed when available)
        self.mood_memory = {}
        self.intent_memory = {}
        
        logger.info("üöÄ Level 13 Customer Context Service initialized - Production Ready")
    
    async def initialize(self):
        """Initialize all managers - must complete before accepting requests"""
        logger.info("üîß Initializing all managers...")
        
        try:
            await self.config_manager.initialize()
            await self.history_manager.initialize()
            logger.info("‚úÖ All managers initialized successfully")
        except Exception as e:
            logger.error(f"‚ùå Manager initialization failed: {e}")
            raise
    
    async def cleanup(self):
        """Cleanup all resources"""
        logger.info("üßπ Cleaning up resources...")
        
        try:
            await self.config_manager.close()
            await self.history_manager.close()
            logger.info("‚úÖ All resources cleaned up")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Cleanup warning: {e}")
    
    async def get_metrics_dict(self) -> Dict[str, Any]:
        """Get metrics in dictionary format (for HTTP endpoint)"""
        return await self.metrics.get_stats()
    
    def _context_to_pb(self, context: ConversationContext) -> pb.ConversationContext:
        """Convert ConversationContext to protobuf message"""
        try:
            entities_pb = []
            for entity in context.entities:
                entity_pb = pb.ConversationEntity(
                    entity_type=entity.entity_type or "",
                    entity_value=entity.entity_name or "",
                    entity_text=json.dumps(entity.entity_details) if hasattr(entity, 'entity_details') else "",
                    confidence=getattr(entity, 'focus_score', 0.0)
                )
                entities_pb.append(entity_pb)
            
            return pb.ConversationContext(
                session_id=context.session_id or "",
                user_id="",
                tenant_id=context.tenant_id or "",
                entities=entities_pb,
                turns=[],
                created_at=int(context.created_at.timestamp()) if context.created_at else int(time.time()),
                updated_at=int(context.updated_at.timestamp()) if context.updated_at else int(time.time())
            )
        except Exception as e:
            logger.error(f"Error converting context to pb: {e}")
            return pb.ConversationContext()
    
    # Apply telemetry to ALL RPC methods for consistency
    
    #@telemetry
    async def CreateContext(self, request: pb.CreateContextRequest, context) -> pb.CreateContextResponse:
        """Create new conversation context"""
        try:
            logger.info(f"üì• CreateContext: session={request.session_id}, tenant={request.tenant_id}")
            
            conv_context = await self.context_manager.create_context(
                request.session_id, request.tenant_id, request.ttl_seconds or 3600
            )

            return pb.CreateContextResponse(
                success=True,
                message=f"Context created for session {request.session_id}",
                session_id=request.session_id,
                created_timestamp=int(time.time() * 1000)
            )

            
        except Exception as e:
            logger.error(f"‚ùå Error in CreateContext: {e}")
            return pb.CreateContextResponse(
                success=False,
                message=f"Error creating context: {str(e)}",
                session_id="",
                created_timestamp=0
            )



    
    #@telemetry
    async def UpdateContext(self, request: pb.UpdateContextRequest, context) -> pb.UpdateContextResponse:
        """Update conversation context with new turn"""
        try:
            logger.info(f"üì• UpdateContext: session={request.session_id}, query='{request.user_query}'")
            
            # Get tenant config for history limits
            config = await self.config_manager.get_tenant_config(request.tenant_id)
            
            # Update conversation history
            await self.history_manager.add_message(
                request.tenant_id, 
                request.session_id, 
                request.user_query,
                config.max_history_turns
            )
            
            # Extract entities from query
            extracted = self.entity_extractor.extract_all_entities(request.user_query)
            context_entities = self.entity_extractor.prepare_context_entities(extracted)
            
            # Add entities from request
            if hasattr(request, 'entities') and request.entities:
                context_entities.append({
                    "type": "provided",
                    "name": request.entities,
                    "details": {}
                })
            
            # Update context
            conv_context = await self.context_manager.update_context(
                request.session_id, request.tenant_id, request.user_query, context_entities
            )
            
            logger.info(f"‚úÖ Context updated: turn {conv_context.turn_count}, entities: {len(conv_context.entities)}")
            
            return pb.UpdateContextResponse(
                success=True,
                message=f"Context updated for turn {conv_context.turn_count}"
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error in UpdateContext: {e}")
            return pb.UpdateContextResponse(
                success=False,
                message=f"Error updating context: {str(e)}"
            )
    
    # ========== LEVEL 13 TIER 1: EMOTIONAL & INTENT INTELLIGENCE ==========
    

    def analyze_emotional_state(self, message: str, tenant_id: str) -> Tuple[str, float]:
        """
        üé≠ ENHANCED: AI-powered emotional state analysis with improved sensitivity
        Analyze user message for emotional state using keyword patterns
        Returns: (detected_mood, confidence)
        """
        try:
            text_lower = message.lower()
            
            # Enhanced Indonesian emotional patterns with broader coverage
            mood_patterns = {
                'marah': ['marah', 'kesel', 'bete', 'jengkel', 'sewot', 'dongkol', 'geram', 'benci', 'muak'],
                'senang': ['senang', 'gembira', 'bahagia', 'excited', 'happy', 'suka', 'mantap', 'bagus', 'oke'],
                'sedih': ['sedih', 'kecewa', 'galau', 'down', 'murung', 'patah hati', 'hancur', 'ditolak'],
                'bingung': ['bingung', 'confused', 'tidak mengerti', 'gak paham', 'gimana', 'bagaimana caranya'],
                'frustrated': ['frustasi', 'capek', 'lelah', 'menyerah', 'putus asa', 'ribet', 'susah', 'sulit'],
                'takut': ['takut', 'khawatir', 'cemas', 'nervous', 'deg-degan', 'gugup'],
                'neutral': ['biasa', 'normal', 'oke', 'baik', 'info', 'tanya']
            }
            
            # Enhanced scoring with partial matches and context
            mood_scores = {}
            for mood, keywords in mood_patterns.items():
                score = 0
                for keyword in keywords:
                    # Full word match gets higher score
                    if f' {keyword} ' in f' {text_lower} ':
                        score += 2
                    # Partial match gets lower score
                    elif keyword in text_lower:
                        score += 1
                mood_scores[mood] = score
            
            # Contextual boost for emotional indicators
            if any(word in text_lower for word in ['banget', 'sekali', 'sangat', 'amat']):
                for mood in ['marah', 'sedih', 'bingung', 'frustrated']:
                    if mood_scores.get(mood, 0) > 0:
                        mood_scores[mood] += 2
            
            # Find highest scoring mood
            detected_mood = max(mood_scores, key=mood_scores.get) if mood_scores else 'neutral'
            confidence = min(mood_scores.get(detected_mood, 0) * 0.2, 0.95)
            
            # Minimum confidence threshold
            if confidence < 0.3:
                detected_mood = 'neutral'
                confidence = 0.3
            
            # Boost confidence for clear emotional indicators
            if any(indicator in text_lower for indicator in ['banget', 'sekali', 'sangat']):
                confidence = min(confidence + 0.3, 1.0)
            
            return detected_mood, confidence
            
        except Exception as e:
            logger.error(f"Error in analyze_emotional_state: {e}")
            return 'neutral', 0.0


    #@telemetry
    async def SetConversationMood(self, request: pb.SetConversationMoodRequest, context) -> pb.SetConversationMoodResponse:
        """üé≠ ENHANCED: AI-powered emotional state analysis"""
        try:
            session_id = request.session_id
            tenant_id = request.tenant_id
            message = getattr(request, 'message', '')
            
            logger.info(f"üé≠ SetConversationMood: session={session_id}, analyzing message: {message[:50]}...")
            
            # AI-POWERED MOOD ANALYSIS
            detected_mood, confidence = self.analyze_emotional_state(message, tenant_id)
            
            # Store in context memory
            mood_key = f"mood:{tenant_id}:{session_id}"
            previous_mood = self.mood_memory.get(mood_key, 'neutral')
            self.mood_memory[mood_key] = detected_mood
            
            logger.info(f"‚úÖ AI Mood analysis: {previous_mood} ‚Üí {detected_mood} (confidence: {confidence:.2f})")
            
            return pb.SetConversationMoodResponse(
                success=True,
                message=f"AI mood analysis: {detected_mood} (confidence: {confidence:.2f})",
                detected_mood=detected_mood,
                mood_confidence=confidence,
                previous_mood=previous_mood
            )
            
        except Exception as e:
            logger.error(f"‚ùå SetConversationMood failed: {e}")
            return pb.SetConversationMoodResponse(
                success=False,
                message=f"Mood analysis failed: {str(e)}",
                detected_mood="neutral",
                mood_confidence=0.0
            )
    async def TrackUserIntent(self, request: pb.TrackUserIntentRequest, context) -> pb.TrackUserIntentResponse:
        """Track user intent progression with tenant-specific patterns"""
        try:
            logger.info(f"üéØ TrackUserIntent: session={request.session_id}, intent={request.intent}")
            
            # Generic memory key
            intent_key = f"intents:{request.tenant_id}:{request.session_id}"
            intent_history = self.intent_memory.get(intent_key, [])
            intent_history.append(request.intent)
            
            # Keep last 10 intents
            if len(intent_history) > 10:
                intent_history = intent_history[-10:]
            
            self.intent_memory[intent_key] = intent_history
            
            # Get response style using tenant config
            _, _, response_style = await self.intelligence.track_intent_progression(
                request.intent, intent_history[:-1], request.tenant_id
            )
            
            return pb.TrackUserIntentResponse(
                success=True,
                message=f"Intent tracked: {request.intent}",
                recommended_response_style=response_style,
                intent_history=intent_history
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error in TrackUserIntent: {e}")
            return pb.TrackUserIntentResponse(
                success=False,
                message=f"Error tracking intent: {str(e)}",
                recommended_response_style="default",
                intent_history=[]
            )
    
    #@telemetry
    async def GetConversationFlow(self, request: pb.GetConversationFlowRequest, context) -> pb.GetConversationFlowResponse:
        """Analyze conversation topic progression and flow quality"""
        try:
            logger.info(f"üîÑ GetConversationFlow: session={request.session_id}")
            
            history = await self.history_manager.get_history(request.session_id, request.tenant_id)
            
            # Simple flow analysis (can be enhanced)
            if not history:
                return pb.GetConversationFlowResponse(
                    success=True,
                    topic_progression=[],
                    current_topic="none",
                    suggested_next_topic="greeting",
                    flow_quality_score=0.0
                )
            
            # Extract topics (simplified)
            topics = []
            for msg in history:
                words = msg.lower().split()
                for word in words:
                    if len(word) > 4 and word not in ['yang', 'untuk', 'dengan', 'adalah']:
                        topics.append(word)
            
            unique_topics = list(set(topics))[:5]
            current_topic = unique_topics[0] if unique_topics else 'general'
            flow_score = min(1.0, len(unique_topics) / 3.0)
            
            return pb.GetConversationFlowResponse(
                success=True,
                topic_progression=unique_topics,
                current_topic=current_topic,
                suggested_next_topic=f"follow_up_on_{current_topic}",
                flow_quality_score=flow_score
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error in GetConversationFlow: {e}")
            return pb.GetConversationFlowResponse(
                success=False,
                topic_progression=[],
                current_topic="error",
                suggested_next_topic="recovery",
                flow_quality_score=0.0
            )
    
    #@telemetry
    async def PredictNextUserQuestion(self, request: pb.PredictNextUserQuestionRequest, context) -> pb.PredictNextUserQuestionResponse:
        """Predict likely next user questions proactively"""
        try:
            logger.info(f"üîÆ PredictNextUserQuestion: session={request.session_id}")
            
            history = await self.history_manager.get_history(request.session_id, request.tenant_id)
            current_query = history[0] if history else ""  # Latest message first in Redis list
            
            # Simple prediction logic
            predictions = []
            query_lower = current_query.lower()
            
            if any(word in query_lower for word in ['harga', 'berapa', 'biaya']):
                predictions.extend([
                    'Apakah ada diskon?',
                    'Bagaimana cara pembayarannya?',
                    'Apakah bisa cicilan?'
                ])
            elif any(word in query_lower for word in ['produk', 'barang', 'item']):
                predictions.extend([
                    'Apakah masih ada stok?',
                    'Bagaimana kualitasnya?',
                    'Berapa lama pengirimannya?'
                ])
            else:
                predictions.extend([
                    'Bisakah dijelaskan lebih detail?',
                    'Apakah ada pilihan lain?',
                    'Bagaimana cara selanjutnya?'
                ])
            
            proactive_responses = [f"Anda mungkin akan bertanya: {q}" for q in predictions[:3]]
            
            return pb.PredictNextUserQuestionResponse(
                success=True,
                likely_questions=predictions[:3],
                suggested_proactive_responses=proactive_responses,
                prediction_confidence=0.75
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error in PredictNextUserQuestion: {e}")
            return pb.PredictNextUserQuestionResponse(
                success=False,
                likely_questions=[],
                suggested_proactive_responses=[],
                prediction_confidence=0.0
            )
    
    # ========== ADD ALL OTHER LEVEL 13 METHODS WITH #@telemetry ==========
    
    #@telemetry
    async def DisambiguateEntity(self, request: pb.DisambiguateEntityRequest, context) -> pb.DisambiguateEntityResponse:
        """üß© ENHANCED: Indonesian conversation reference resolution"""
        try:
            logger.info(f"üß© DisambiguateEntity: {request.ambiguous_entity}")
            
            entity = request.ambiguous_entity.lower()
            context_hint = request.context_hint.lower()
            
            # üáÆüá© INDONESIAN CONVERSATION REFERENCE PATTERNS
            if any(pattern in entity for pattern in ['yang tadi', 'yang itu', 'itu tadi']):
                logger.info(f"üîç Indonesian reference detected: '{entity}'")
                
                # For conversation references, default to banking general info
                clarified = 'banking_general_info'
                entity_type = 'banking'
                confidence = 0.7
                
                logger.info(f"‚úÖ Reference resolved: '{entity}' ‚Üí '{clarified}' (confidence: {confidence:.2f})")
                    
            elif any(pattern in entity for pattern in ['yang pertama', 'yang kedua', 'yang ketiga']):
                logger.info(f"üî¢ Ordinal reference: '{entity}'")
                # Ordinal references
                if 'pertama' in entity:
                    clarified = 'tahapan_xpresi'  # First banking option
                    entity_type = 'banking_product'
                elif 'kedua' in entity:
                    clarified = 'tahapan_bca'     # Second banking option
                    entity_type = 'banking_product'  
                elif 'ketiga' in entity:
                    clarified = 'tabunganku'      # Third banking option
                    entity_type = 'banking_product'
                confidence = 0.85
                
                logger.info(f"‚úÖ Ordinal resolved: '{entity}' ‚Üí '{clarified}' (confidence: {confidence:.2f})")
                
            # üè¶ BANKING SPECIFIC PATTERNS
            elif any(keyword in entity for keyword in ['tahapan', 'xpresi', 'tabungan', 'rekening']):
                logger.info(f"üè¶ Banking entity: '{entity}'")
                if 'tahapan' in entity or 'xpresi' in entity:
                    clarified = 'tahapan_xpresi'
                    entity_type = 'banking_product'
                elif 'tabungan' in entity:
                    clarified = 'savings_account'
                    entity_type = 'banking_product'
                elif 'rekening' in entity:
                    clarified = 'bank_account'
                    entity_type = 'banking_product'
                confidence = 0.9
                
                logger.info(f"‚úÖ Banking resolved: '{entity}' ‚Üí '{clarified}' (confidence: {confidence:.2f})")
                
            else:
                # üîÑ FALLBACK: Instead of generic, use banking context
                logger.info(f"üîÑ Fallback for: '{entity}'")
                clarified = 'banking_general_info'
                entity_type = "banking"
                confidence = 0.6
                
                logger.info(f"‚úÖ Fallback resolved: '{entity}' ‚Üí '{clarified}' (confidence: {confidence:.2f})")
            
            # üéØ BANKING-FOCUSED ALTERNATIVES
            alternatives = ['tahapan_xpresi', 'tahapan_bca', 'tabunganku']
            
            return pb.DisambiguateEntityResponse(
                success=True,
                clarified_entity=clarified,
                entity_type=entity_type,
                disambiguation_confidence=confidence,
                alternative_interpretations=alternatives
            )
            
        except Exception as e:
            logger.error(f"‚ùå DisambiguateEntity error: {e}")
            return pb.DisambiguateEntityResponse(
                success=False,
                clarified_entity="disambiguation_failed",
                entity_type="unknown",
                disambiguation_confidence=0.0,
                alternative_interpretations=[]
            )

class MetricsHTTPServer:
    """HTTP server for exposing metrics endpoint"""
    
    def __init__(self, servicer: CustContextServicer, port: int = 8080):
        self.servicer = servicer
        self.port = port
        self.app = web.Application()
        self.app.router.add_get('/metrics', self.metrics_handler)
        self.app.router.add_get('/health', self.health_handler)
        self.runner = None
        self.site = None
    
    async def metrics_handler(self, request) -> web.Response:
        """HTTP endpoint for metrics (Enhanced Prometheus format with tenant labels)"""
        try:
            stats = await self.servicer.get_metrics_dict()
            
            # Convert to Prometheus format with enhanced labels
            prometheus_metrics = []
            prometheus_metrics.append("# HELP grpc_method_calls_total Total gRPC method calls")
            prometheus_metrics.append("# TYPE grpc_method_calls_total counter")
            
            for method, data in stats.items():
                for status, count in data["calls"].items():
                    prometheus_metrics.append(f'grpc_method_calls_total{{method="{method}",status="{status}",service="cust_context"}} {count}')
            
            prometheus_metrics.append("")
            prometheus_metrics.append("# HELP grpc_method_duration_seconds gRPC method duration")
            prometheus_metrics.append("# TYPE grpc_method_duration_seconds summary")
            
            for method, data in stats.items():
                prometheus_metrics.append(f'grpc_method_duration_seconds_avg{{method="{method}",service="cust_context"}} {data["avg_latency"]:.6f}')
                prometheus_metrics.append(f'grpc_method_duration_seconds_max{{method="{method}",service="cust_context"}} {data["max_latency"]:.6f}')
                prometheus_metrics.append(f'grpc_method_duration_seconds_min{{method="{method}",service="cust_context"}} {data["min_latency"]:.6f}')
                prometheus_metrics.append(f'grpc_method_duration_seconds{{method="{method}",service="cust_context",quantile="0.95"}} {data["p95_latency"]:.6f}')
            
            prometheus_metrics.append("")
            return web.Response(text="\n".join(prometheus_metrics), content_type="text/plain")
            
        except Exception as e:
            logger.error(f"Metrics endpoint error: {e}")
            return web.Response(text="Error generating metrics", status=500)
    
    async def health_handler(self, request) -> web.Response:
        """HTTP health check endpoint"""
        return web.json_response({"status": "healthy", "timestamp": int(time.time())})
    
    async def start(self):
        """Start HTTP metrics server"""
        try:
            self.runner = web.AppRunner(self.app)
            await self.runner.setup()
            self.site = web.TCPSite(self.runner, '0.0.0.0', self.port)
            await self.site.start()
            logger.info(f"üìä HTTP metrics server started on port {self.port}")
        except Exception as e:
            logger.error(f"Failed to start HTTP metrics server: {e}")
    
    async def stop(self):
        """Stop HTTP metrics server"""
        if self.site:
            await self.site.stop()
        if self.runner:
            await self.runner.cleanup()
        logger.info("üìä HTTP metrics server stopped")


class HealthServicer(health_pb2_grpc.HealthServicer):
    """Standard gRPC health check servicer"""
    async def Check(self, request, context):
        return health_pb2.HealthCheckResponse(
            status=health_pb2.HealthCheckResponse.SERVING
        )


async def serve():
    """Start the production-optimized Level 13 Customer Context gRPC Server"""
    # Initialize server
    server = aio.server()
    
    # Create servicer
    servicer = CustContextServicer()
    
    # CRITICAL: Initialize all managers BEFORE accepting requests
    logger.info("üîß Initializing servicer managers...")
    await servicer.initialize()
    
    # Add servicers to gRPC server
    pb_grpc.add_CustContextServiceServicer_to_server(servicer, server)
    health_pb2_grpc.add_HealthServicer_to_server(HealthServicer(), server)
    
    # Configure gRPC server
    listen_addr = f"[::]:{settings.GRPC_PORT}"
    server.add_insecure_port(listen_addr)
    
    # Start HTTP metrics server
    metrics_server = MetricsHTTPServer(servicer, port=8080)
    await metrics_server.start()
    
    # Enhanced graceful shutdown handler with proper order
    async def shutdown_handler():
        logger.info("üõë Shutting down Level 13 Customer Context Service...")
        
        # Step 1: Stop HTTP metrics server first
        await metrics_server.stop()
        
        # Step 2: Stop accepting new gRPC requests 
        server.stop(grace=10.0)
        
        # Step 3: Cleanup service resources after requests are drained
        await servicer.cleanup()
        
        logger.info("‚úÖ Graceful shutdown completed")
    
    # Register signal handlers
    loop = asyncio.get_event_loop()
    for sig in (signal.SIGTERM, signal.SIGINT):
        loop.add_signal_handler(sig, lambda: asyncio.create_task(shutdown_handler()))
    
    # Start gRPC server
    logger.info("üöÄ Starting Level 13 'DEWA' Customer Context Service...")
    await server.start()
    logger.info(f"üéØ Level 13 gRPC Service listening on {listen_addr}")
    logger.info(f"üìä HTTP Metrics endpoint: http://localhost:8080/metrics")
    logger.info(f"‚ù§Ô∏è HTTP Health endpoint: http://localhost:8080/health")
    logger.info("‚ú® Production-Grade Features ACTIVE:")
    logger.info("  üîß Tenant-specific configurations with Redis caching & thread-safe access")
    logger.info("  üíæ Redis-backed conversation history with bulk operations & fallback")
    logger.info("  üìä Comprehensive telemetry with error classification & P95 latencies")
    logger.info("  üèóÔ∏è Generic tenant handling (zero hard-coding)")
    logger.info("  üõ°Ô∏è Connection cleanup, graceful shutdown & resource management")
    logger.info("  üåê HTTP metrics endpoint for Prometheus integration")
    logger.info("  ‚ö° All 22 methods with consistent telemetry coverage")
    
    try:
        await server.wait_for_termination()
    except KeyboardInterrupt:
        logger.info("üõë Server interrupted by user")
        await shutdown_handler()
    finally:
        logger.info("‚úÖ Level 13 Customer Context Service stopped gracefully")


if __name__ == "__main__":
    # Set environment for optimal performance
    os.environ.setdefault('PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION', 'python')
    
    # Run the production-optimized Level 13 service
    asyncio.run(serve())