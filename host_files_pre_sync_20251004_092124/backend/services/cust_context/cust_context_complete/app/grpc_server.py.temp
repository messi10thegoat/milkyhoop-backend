from backend.api_gateway.libs.milkyhoop_prisma import Prisma
import asyncio
import signal
import logging
import os
import json
import time
import redis.asyncio as redis
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from functools import wraps
import grpc
from grpc import aio
from grpc_health.v1 import health, health_pb2, health_pb2_grpc

# Import generated stubs
from app import cust_context_pb2_grpc as pb_grpc
from app import cust_context_pb2 as pb

# Import our services
from app.services.context_manager import CustomerContextManager
from app.services.entity_extractor import CustomerEntityExtractor
from app.models.conversation import ConversationContext, ConversationEntity
from app.config import settings

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)
logger = logging.getLogger("CustContextLevel13")

# ========== CONFIGURATION SETTINGS ==========

class Settings:
    """Centralized configuration settings"""
    REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")
    GRPC_PORT = int(os.getenv("GRPC_PORT", "5008"))
    
    # TTL Settings (configurable via environment)
    REDIS_CACHE_TTL = int(os.getenv("REDIS_CACHE_TTL", "300"))  # 5 minutes
    HISTORY_TTL = int(os.getenv("HISTORY_TTL", "3600"))  # 1 hour
    CONFIG_CACHE_TTL = int(os.getenv("CONFIG_CACHE_TTL", "300"))  # 5 minutes
    
    # Limits
    MAX_HISTORY_TURNS = int(os.getenv("MAX_HISTORY_TURNS", "20"))
    MAX_MEMORY_SESSIONS = int(os.getenv("MAX_MEMORY_SESSIONS", "1000"))
    MAX_LATENCY_SAMPLES = int(os.getenv("MAX_LATENCY_SAMPLES", "100"))

settings = Settings()

# ========== TENANT CONFIGURATION SYSTEM ==========

@dataclass
class TenantConfig:
    """Tenant-specific configuration for conversation intelligence"""
    tenant_id: str
    language: str = "id"
    mood_patterns: Dict[str, List[str]] = None
    intent_patterns: Dict[str, List[str]] = None
    product_patterns: Dict[str, List[str]] = None
    frustration_indicators: List[str] = None
    response_style: str = "friendly_professional"
    max_history_turns: int = 20
    conversation_ttl: int = 3600
    
    def __post_init__(self):
        """Initialize default patterns if not provided"""
        if self.mood_patterns is None:
            self.mood_patterns = DEFAULT_MOOD_PATTERNS
        if self.intent_patterns is None:
            self.intent_patterns = DEFAULT_INTENT_PATTERNS
        if self.product_patterns is None:
            self.product_patterns = DEFAULT_PRODUCT_PATTERNS
        if self.frustration_indicators is None:
            self.frustration_indicators = DEFAULT_FRUSTRATION_INDICATORS

# Default patterns (fallback for all tenants)
DEFAULT_MOOD_PATTERNS = {
    'happy': ['senang', 'gembira', 'suka', 'bagus', 'mantap', 'oke', 'terima kasih', 'makasih'],
    'frustrated': ['kesal', 'bingung', 'susah', 'ribet', 'lama', 'lambat', 'error', 'gagal', 'tidak bisa'],
    'curious': ['bagaimana', 'gimana', 'apa itu', 'kenapa', 'mengapa', 'bisa tidak', 'bisakah'],
    'urgent': ['segera', 'cepat', 'urgent', 'penting', 'butuh sekarang', 'tolong'],
    'confused': ['bingung', 'tidak mengerti', 'tidak paham', 'maksudnya', 'apa maksudnya']
}

DEFAULT_INTENT_PATTERNS = {
    'browsing': ['lihat', 'cek', 'info', 'tanya', 'apa ada'],
    'comparing': ['bandingkan', 'beda', 'mana yang', 'lebih baik', 'vs'],
    'buying': ['beli', 'order', 'pesan', 'checkout', 'bayar', 'harga'],
    'support': ['help', 'bantuan', 'masalah', 'error', 'tidak bisa', 'trouble']
}

DEFAULT_PRODUCT_PATTERNS = {
    'clothing': ['baju', 'kemeja', 'kaos', 'celana', 'dress', 'jaket'],
    'electronics': ['hp', 'laptop', 'komputer', 'gadget', 'elektronik'],
    'services': ['konsultasi', 'konseling', 'terapi', 'layanan', 'jasa']
}

DEFAULT_FRUSTRATION_INDICATORS = [
    'tidak bisa', 'gagal', 'error', 'bermasalah', 'ribet', 'susah', 
    'lama', 'lambat', 'tidak jelas', 'bingung terus'
]

class TenantConfigManager:
    """Thread-safe tenant configuration manager with Redis caching"""
    
    def __init__(self):
        self.redis_client = None
        self.config_cache = {}
        self._cache_lock = asyncio.Lock()  # Thread-safe cache access
    
    async def initialize(self):
        """Initialize Redis connection"""
        try:
            self.redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True)
            await self.redis_client.ping()
            logger.info("ðŸ”§ TenantConfigManager initialized with Redis")
        except Exception as e:
            logger.warning(f"âš ï¸ Redis not available, using memory cache: {e}")
            self.redis_client = None
    
    async def close(self):
        """Cleanup Redis connection"""
        if self.redis_client:
            try:
                await self.redis_client.close()
                logger.info("ðŸ”Œ Redis connection closed")
            except Exception as e:
                logger.warning(f"Error closing Redis: {e}")
    
    def _memory_key(self, tenant_id: str, *suffix) -> str:
        """Generate consistent memory keys"""
        parts = [tenant_id] + list(suffix)
        return ":".join(parts)
    
    async def get_tenant_config(self, tenant_id: str) -> TenantConfig:
        """Thread-safe tenant configuration retrieval with caching"""
        cache_key = f"tenant_config:{tenant_id}"
        
        # Thread-safe cache access
        async with self._cache_lock:
            # Try memory cache first
            if cache_key in self.config_cache:
                cached_time, config = self.config_cache[cache_key]
                if time.time() - cached_time < settings.CONFIG_CACHE_TTL:
                    return config
        
        # Try Redis if available
        if self.redis_client:
            try:
                cached_data = await self.redis_client.get(cache_key)
                if cached_data:
                    config_dict = json.loads(cached_data)
                    config = TenantConfig(**config_dict)
                    
                    # Update memory cache (thread-safe)
                    async with self._cache_lock:
                        self.config_cache[cache_key] = (time.time(), config)
                    return config
            except Exception as e:
                logger.warning(f"Redis cache miss for {tenant_id}: {e}")
        
        # Fallback to default config
        config = TenantConfig(tenant_id=tenant_id)
        
        # Cache the result (thread-safe)
        async with self._cache_lock:
            self.config_cache[cache_key] = (time.time(), config)
        
        if self.redis_client:
            try:
                await self.redis_client.setex(
                    cache_key, 
                    settings.CONFIG_CACHE_TTL, 
                    json.dumps(asdict(config))
                )
            except Exception as e:
                logger.warning(f"Failed to cache config: {e}")
        
        return config

# ========== CONVERSATION HISTORY MANAGER ==========

class ConversationHistoryManager:
    """Thread-safe conversation history with Redis backend and bulk operations"""
    
    def __init__(self):
        self.redis_client = None
        self.memory_fallback = {}
        self._memory_lock = asyncio.Lock()  # Thread-safe memory access
    
    async def initialize(self):
        """Initialize Redis connection"""
        try:
            self.redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True)
            await self.redis_client.ping()
            logger.info("ðŸ’¾ ConversationHistoryManager initialized with Redis")
        except Exception as e:
            logger.warning(f"âš ï¸ Redis not available, using memory fallback: {e}")
            self.redis_client = None
    
    async def close(self):
        """Cleanup Redis connection"""
        if self.redis_client:
            try:
                await self.redis_client.close()
                logger.info("ðŸ”Œ History Redis connection closed")
            except Exception as e:
                logger.warning(f"Error closing history Redis: {e}")
    
    def _history_key(self, tenant_id: str, session_id: str) -> str:
        """Generate consistent history keys"""
        return f"history:{tenant_id}:{session_id}"
    
    async def get_history(self, tenant_id: str, session_id: str) -> List[str]:
        """Thread-safe conversation history retrieval"""
        key = self._history_key(tenant_id, session_id)
        
        if self.redis_client:
            try:
                messages = await self.redis_client.lrange(key, 0, -1)
                return messages or []
            except Exception as e:
                logger.warning(f"Redis get_history failed: {e}")
        
        # Thread-safe memory fallback
        async with self._memory_lock:
            return self.memory_fallback.get(key, [])
    
    async def add_message(self, tenant_id: str, session_id: str, message: str, max_turns: Optional[int] = None) -> None:
        """Thread-safe message addition with bulk Redis operations"""
        if max_turns is None:
            max_turns = settings.MAX_HISTORY_TURNS
            
        key = self._history_key(tenant_id, session_id)
        
        if self.redis_client:
            try:
                # Use Redis pipeline for bulk operations
                pipe = self.redis_client.pipeline()
                pipe.lpush(key, message)
                pipe.ltrim(key, 0, max_turns - 1)
                pipe.expire(key, settings.HISTORY_TTL)
                await pipe.execute()
                return
            except Exception as e:
                logger.warning(f"Redis add_message failed: {e}")
        
        # Thread-safe memory fallback
        async with self._memory_lock:
            if key not in self.memory_fallback:
                self.memory_fallback[key] = []
            
            self.memory_fallback[key].insert(0, message)
            if len(self.memory_fallback[key]) > max_turns:
                self.memory_fallback[key] = self.memory_fallback[key][:max_turns]
            
            # Prevent memory bloat
            if len(self.memory_fallback) > settings.MAX_MEMORY_SESSIONS:
                oldest_keys = list(self.memory_fallback.keys())[:100]
                for old_key in oldest_keys:
                    del self.memory_fallback[old_key]
    
    async def clear_history(self, tenant_id: str, session_id: str) -> None:
        """Thread-safe conversation history cleanup"""
        key = self._history_key(tenant_id, session_id)
        
        if self.redis_client:
            try:
                await self.redis_client.delete(key)
            except Exception as e:
                logger.warning(f"Redis clear_history failed: {e}")
        
        async with self._memory_lock:
            if key in self.memory_fallback:
                del self.memory_fallback[key]

# ========== TELEMETRY & METRICS ==========

class MetricsCollector:
    """Enhanced metrics collection with error classification"""
    
    # Error classification
    NETWORK_ERRORS = (ConnectionError, TimeoutError, redis.RedisError)
    LOGIC_ERRORS = (ValueError, KeyError, TypeError, AttributeError)
    
    def __init__(self):
        self.method_calls = {}
        self.method_latencies = {}
        self.error_counts = {}
        self._metrics_lock = asyncio.Lock()  # Thread-safe metrics
    
    async def record_call(self, method_name: str, latency: float, success: bool, error: Optional[Exception] = None) -> None:
        """Thread-safe method call recording with error classification"""
        async with self._metrics_lock:
            # Call counts
            if method_name not in self.method_calls:
                self.method_calls[method_name] = {"success": 0, "network_error": 0, "logic_error": 0, "unknown_error": 0}
            
            if success:
                self.method_calls[method_name]["success"] += 1
            else:
                # Classify error type
                if error and isinstance(error, self.NETWORK_ERRORS):
                    self.method_calls[method_name]["network_error"] += 1
                elif error and isinstance(error, self.LOGIC_ERRORS):
                    self.method_calls[method_name]["logic_error"] += 1
                else:
                    self.method_calls[method_name]["unknown_error"] += 1
            
            # Latencies (bounded list)
            if method_name not in self.method_latencies:
                self.method_latencies[method_name] = []
            
            self.method_latencies[method_name].append(latency)
            # Keep only last N measurements
            if len(self.method_latencies[method_name]) > settings.MAX_LATENCY_SAMPLES:
                self.method_latencies[method_name] = self.method_latencies[method_name][-settings.MAX_LATENCY_SAMPLES:]
    
    async def get_stats(self) -> Dict[str, Any]:
        """Thread-safe metrics statistics"""
        async with self._metrics_lock:
            stats = {}
            for method, calls in self.method_calls.items():
                latencies = self.method_latencies.get(method, [])
                stats[method] = {
                    "calls": calls,
                    "avg_latency": sum(latencies) / len(latencies) if latencies else 0,
                    "max_latency": max(latencies) if latencies else 0,
                    "min_latency": min(latencies) if latencies else 0,
                    "p95_latency": sorted(latencies)[int(len(latencies) * 0.95)] if latencies else 0
                }
            return stats

def telemetry(metrics_collector: MetricsCollector):
    """Enhanced decorator with error classification"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            method_name = func.__name__
            success = True
            error = None
            
            try:
                result = await func(*args, **kwargs)
                return result
            except Exception as e:
                success = False
                error = e
                logger.error(f"Method {method_name} failed: {e}")
                raise
            finally:
                latency = time.time() - start_time
                await metrics_collector.record_call(method_name, latency, success, error)
                logger.debug(f"ðŸ“Š {method_name}: {latency:.3f}s ({'âœ…' if success else 'âŒ'})")
        
        return wrapper
    return decorator

# ========== ENHANCED CONVERSATION INTELLIGENCE ==========

class ConversationIntelligence:
    """Enhanced conversation intelligence with tenant-specific patterns"""
    
    def __init__(self, config_manager: TenantConfigManager):
        self.config_manager = config_manager
    
    async def detect_mood(self, text: str, tenant_id: str) -> Tuple[str, float, str]:
        """Detect user mood with tenant-specific patterns"""
        config = await self.config_manager.get_tenant_config(tenant_id)
        text_lower = text.lower()
        mood_scores = {}
        
        for mood, patterns in config.mood_patterns.items():
            score = sum(1 for pattern in patterns if pattern in text_lower)
            if score > 0:
                mood_scores[mood] = score / len(patterns)
        
        if not mood_scores:
            return 'neutral', 0.5, 'No clear mood indicators found'
        
        detected_mood = max(mood_scores, key=mood_scores.get)
        confidence = mood_scores[detected_mood]
        reason = f"Detected patterns matching {detected_mood} mood"
        
        return detected_mood, confidence, reason
    
    async def track_intent_progression(self, text: str, previous_intents: List[str], tenant_id: str) -> Tuple[str, float, str]:
        """Track user intent with tenant-specific patterns"""
        config = await self.config_manager.get_tenant_config(tenant_id)
        text_lower = text.lower()
        intent_scores = {}
        
        for intent, patterns in config.intent_patterns.items():
            score = sum(1 for pattern in patterns if pattern in text_lower)
            if score > 0:
                intent_scores[intent] = score / len(patterns)
        
        if not intent_scores:
            current_intent = 'general_inquiry'
            confidence = 0.3
        else:
            current_intent = max(intent_scores, key=intent_scores.get)
            confidence = intent_scores[current_intent]
        
        # Recommend response style based on intent progression
        if len(previous_intents) > 0 and previous_intents[-1] == 'browsing' and current_intent == 'buying':
            response_style = 'conversion_focused'
        elif current_intent == 'support':
            response_style = 'problem_solving'
        elif current_intent == 'comparing':
            response_style = 'informative_detailed'
        else:
            response_style = config.response_style
        
        return current_intent, confidence, response_style
    
    async def detect_products_mentioned(self, text: str, tenant_id: str) -> Dict[str, Any]:
        """Detect products with tenant-specific patterns"""
        config = await self.config_manager.get_tenant_config(tenant_id)
        text_lower = text.lower()
        detected_products = []
        categories = []
        confidences = []
        
        for category, patterns in config.product_patterns.items():
            for pattern in patterns:
                if pattern in text_lower:
                    detected_products.append(pattern)
                    categories.append(category)
                    confidences.append(0.8)
        
        return {
            'products': detected_products,
            'categories': list(set(categories)),
            'confidences': confidences
        }
    
    async def detect_frustration_level(self, text: str, conversation_history: List[str], tenant_id: str) -> Dict[str, Any]:
        """Detect frustration with tenant-specific indicators"""
        config = await self.config_manager.get_tenant_config(tenant_id)
        text_lower = text.lower()
        
        frustration_count = sum(1 for indicator in config.frustration_indicators 
                               if indicator in text_lower)
        
        # Check for repeated issues in history
        history_frustration = sum(1 for msg in conversation_history[-3:] 
                                 for indicator in config.frustration_indicators 
                                 if indicator in msg.lower())
        
        total_score = frustration_count + (history_frustration * 0.5)
        
        if total_score >= 3:
            level = 'high'
            actions = ['escalate_to_human', 'offer_direct_help', 'apologize_proactively']
        elif total_score >= 1.5:
            level = 'medium'
            actions = ['provide_clearer_explanation', 'offer_alternative_solution']
        else:
            level = 'low'
            actions = ['continue_normal_flow']
        
        return {
            'level': level,
            'score': total_score,
            'indicators': [ind for ind in config.frustration_indicators if ind in text_lower],
            'recommended_actions': actions
        }

# ========== MAIN SERVICE IMPLEMENTATION ==========

class CustContextServicer(pb_grpc.CustContextServiceServicer):
    """Production-Grade Level 13 Customer Context Service"""
    
    def __init__(self):
        self.context_manager = CustomerContextManager()
        self.entity_extractor = CustomerEntityExtractor()
        
        # Initialize managers
        self.config_manager = TenantConfigManager()
        self.history_manager = ConversationHistoryManager()
        self.metrics = MetricsCollector()
        self.intelligence = ConversationIntelligence(self.config_manager)
        
        # Internal state (Redis-backed when available)
        self.mood_memory = {}
        self.intent_memory = {}
        
        logger.info("ðŸš€ Level 13 Customer Context Service initialized - Production Ready")
    
    async def initialize(self):
        """Initialize all managers - must complete before accepting requests"""
        logger.info("ðŸ”§ Initializing all managers...")
        
        try:
            await self.config_manager.initialize()
            await self.history_manager.initialize()
            logger.info("âœ… All managers initialized successfully")
        except Exception as e:
            logger.error(f"âŒ Manager initialization failed: {e}")
            raise
    
    async def cleanup(self):
        """Cleanup all resources"""
        logger.info("ðŸ§¹ Cleaning up resources...")
        
        try:
            await self.config_manager.close()
            await self.history_manager.close()
            logger.info("âœ… All resources cleaned up")
        except Exception as e:
            logger.warning(f"âš ï¸ Cleanup warning: {e}")
    
    async def get_metrics_dict(self) -> Dict[str, Any]:
        """Get metrics in dictionary format (for HTTP endpoint)"""
        return await self.metrics.get_stats()
    
    def _context_to_pb(self, context: ConversationContext) -> pb.ConversationContext:
        """Convert ConversationContext to protobuf message"""
        try:
            entities_pb = []
            for entity in context.entities:
                entity_pb = pb.ConversationEntity(
                    entity_type=entity.entity_type or "",
                    entity_value=entity.entity_name or "",
                    entity_text=json.dumps(entity.entity_details) if hasattr(entity, 'entity_details') else "",
                    confidence=getattr(entity, 'focus_score', 0.0)
                )
                entities_pb.append(entity_pb)
            
            return pb.ConversationContext(
                session_id=context.session_id or "",
                user_id="",
                tenant_id=context.tenant_id or "",
                entities=entities_pb,
                turns=[],
                created_at=int(context.created_at.timestamp()) if context.created_at else int(time.time()),
                updated_at=int(context.updated_at.timestamp()) if context.updated_at else int(time.time())
            )
        except Exception as e:
            logger.error(f"Error converting context to pb: {e}")
            return pb.ConversationContext()
    
    # Apply telemetry to ALL RPC methods for consistency
    
    @telemetry
    async def CreateContext(self, request: pb.CreateContextRequest, context) -> pb.CreateContextResponse:
        """Create new conversation context"""
        try:
            logger.info(f"ðŸ“¥ CreateContext: session={request.session_id}, tenant={request.tenant_id}")
            
            conv_context = await self.context_manager.create_context(
                request.session_id, request.tenant_id, request.ttl_seconds or 3600
            )
            
            return pb.CreateContextResponse(
                success=True,
                message=f"Context created for session {request.session_id}"
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in CreateContext: {e}")
            return pb.CreateContextResponse(
                success=False,
                message=f"Error creating context: {str(e)}"
            )
    
    @telemetry
    async def UpdateContext(self, request: pb.UpdateContextRequest, context) -> pb.UpdateContextResponse:
        """Update conversation context with new turn"""
        try:
            logger.info(f"ðŸ“¥ UpdateContext: session={request.session_id}, query='{request.user_query}'")
            
            # Get tenant config for history limits
            config = await self.config_manager.get_tenant_config(request.tenant_id)
            
            # Update conversation history
            await self.history_manager.add_message(
                request.tenant_id, 
                request.session_id, 
                request.user_query,
                config.max_history_turns
            )
            
            # Extract entities from query
            extracted = self.entity_extractor.extract_all_entities(request.user_query)
            context_entities = self.entity_extractor.prepare_context_entities(extracted)
            
            # Add entities from request
            if hasattr(request, 'entities') and request.entities:
                context_entities.append({
                    "type": "provided",
                    "name": request.entities,
                    "details": {}
                })
            
            # Update context
            conv_context = await self.context_manager.update_context(
                request.session_id, request.tenant_id, request.user_query, context_entities
            )
            
            logger.info(f"âœ… Context updated: turn {conv_context.turn_count}, entities: {len(conv_context.entities)}")
            
            return pb.UpdateContextResponse(
                success=True,
                message=f"Context updated for turn {conv_context.turn_count}"
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in UpdateContext: {e}")
            return pb.UpdateContextResponse(
                success=False,
                message=f"Error updating context: {str(e)}"
            )
    
    # ========== LEVEL 13 TIER 1: EMOTIONAL & INTENT INTELLIGENCE ==========
    
    @telemetry
    async def SetConversationMood(self, request: pb.SetConversationMoodRequest, context) -> pb.SetConversationMoodResponse:
        """Track and set user emotional state with tenant-specific patterns"""
        try:
            logger.info(f"ðŸŽ­ SetConversationMood: session={request.session_id}, mood={request.mood}")
            
            # Generic memory key
            mood_key = f"mood:{request.tenant_id}:{request.session_id}"
            previous_mood = self.mood_memory.get(mood_key, 'neutral')
            
            # Store new mood
            self.mood_memory[mood_key] = request.mood
            
            logger.info(f"âœ… Mood updated: {previous_mood} â†’ {request.mood}")
            
            return pb.SetConversationMoodResponse(
                success=True,
                message=f"Mood set to {request.mood} (confidence: {request.confidence:.2f})",
                previous_mood=previous_mood
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in SetConversationMood: {e}")
            return pb.SetConversationMoodResponse(
                success=False,
                message=f"Error setting mood: {str(e)}",
                previous_mood="unknown"
            )
    
    @telemetry
    async def TrackUserIntent(self, request: pb.TrackUserIntentRequest, context) -> pb.TrackUserIntentResponse:
        """Track user intent progression with tenant-specific patterns"""
        try:
            logger.info(f"ðŸŽ¯ TrackUserIntent: session={request.session_id}, intent={request.intent}")
            
            # Generic memory key
            intent_key = f"intents:{request.tenant_id}:{request.session_id}"
            intent_history = self.intent_memory.get(intent_key, [])
            intent_history.append(request.intent)
            
            # Keep last 10 intents
            if len(intent_history) > 10:
                intent_history = intent_history[-10:]
            
            self.intent_memory[intent_key] = intent_history
            
            # Get response style using tenant config
            _, _, response_style = await self.intelligence.track_intent_progression(
                request.intent, intent_history[:-1], request.tenant_id
            )
            
            return pb.TrackUserIntentResponse(
                success=True,
                message=f"Intent tracked: {request.intent}",
                recommended_response_style=response_style,
                intent_history=intent_history
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in TrackUserIntent: {e}")
            return pb.TrackUserIntentResponse(
                success=False,
                message=f"Error tracking intent: {str(e)}",
                recommended_response_style="default",
                intent_history=[]
            )
    
    @telemetry
    async def GetConversationFlow(self, request: pb.GetConversationFlowRequest, context) -> pb.GetConversationFlowResponse:
        """Analyze conversation topic progression and flow quality"""
        try:
            logger.info(f"ðŸ”„ GetConversationFlow: session={request.session_id}")
            
            history = await self.history_manager.get_history(request.session_id, request.tenant_id)
            
            # Simple flow analysis (can be enhanced)
            if not history:
                return pb.GetConversationFlowResponse(
                    success=True,
                    topic_progression=[],
                    current_topic="none",
                    suggested_next_topic="greeting",
                    flow_quality_score=0.0
                )
            
            # Extract topics (simplified)
            topics = []
            for msg in history:
                words = msg.lower().split()
                for word in words:
                    if len(word) > 4 and word not in ['yang', 'untuk', 'dengan', 'adalah']:
                        topics.append(word)
            
            unique_topics = list(set(topics))[:5]
            current_topic = unique_topics[0] if unique_topics else 'general'
            flow_score = min(1.0, len(unique_topics) / 3.0)
            
            return pb.GetConversationFlowResponse(
                success=True,
                topic_progression=unique_topics,
                current_topic=current_topic,
                suggested_next_topic=f"follow_up_on_{current_topic}",
                flow_quality_score=flow_score
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in GetConversationFlow: {e}")
            return pb.GetConversationFlowResponse(
                success=False,
                topic_progression=[],
                current_topic="error",
                suggested_next_topic="recovery",
                flow_quality_score=0.0
            )
    
    @telemetry
    async def PredictNextUserQuestion(self, request: pb.PredictNextUserQuestionRequest, context) -> pb.PredictNextUserQuestionResponse:
        """Predict likely next user questions proactively"""
        try:
            logger.info(f"ðŸ”® PredictNextUserQuestion: session={request.session_id}")
            
            history = await self.history_manager.get_history(request.session_id, request.tenant_id)
            current_query = history[0] if history else ""  # Latest message first in Redis list
            
            # Simple prediction logic
            predictions = []
            query_lower = current_query.lower()
            
            if any(word in query_lower for word in ['harga', 'berapa', 'biaya']):
                predictions.extend([
                    'Apakah ada diskon?',
                    'Bagaimana cara pembayarannya?',
                    'Apakah bisa cicilan?'
                ])
            elif any(word in query_lower for word in ['produk', 'barang', 'item']):
                predictions.extend([
                    'Apakah masih ada stok?',
                    'Bagaimana kualitasnya?',
                    'Berapa lama pengirimannya?'
                ])
            else:
                predictions.extend([
                    'Bisakah dijelaskan lebih detail?',
                    'Apakah ada pilihan lain?',
                    'Bagaimana cara selanjutnya?'
                ])
            
            proactive_responses = [f"Anda mungkin akan bertanya: {q}" for q in predictions[:3]]
            
            return pb.PredictNextUserQuestionResponse(
                success=True,
                likely_questions=predictions[:3],
                suggested_proactive_responses=proactive_responses,
                prediction_confidence=0.75
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in PredictNextUserQuestion: {e}")
            return pb.PredictNextUserQuestionResponse(
                success=False,
                likely_questions=[],
                suggested_proactive_responses=[],
                prediction_confidence=0.0
            )
    
    # ========== ADD ALL OTHER LEVEL 13 METHODS WITH @telemetry ==========
    
    @telemetry
    async def DisambiguateEntity(self, request: pb.DisambiguateEntityRequest, context) -> pb.DisambiguateEntityResponse:
        """Handle complex entity disambiguation with context"""
        try:
            logger.info(f"ðŸ§© DisambiguateEntity: {request.ambiguous_entity}")
            
            entity = request.ambiguous_entity.lower()
            context_hint = request.context_hint.lower()
            
            # Simple disambiguation rules
            if 'baju' in entity:
                if 'anak' in context_hint:
                    clarified = 'baju_anak'
                elif 'dewasa' in context_hint or 'pria' in context_hint:
                    clarified = 'baju_pria'
                else:
                    clarified = 'baju_umum'
            elif 'harga' in entity:
                if 'paket' in context_hint:
                    clarified = 'harga_paket'
                elif 'satuan' in context_hint:
                    clarified = 'harga_satuan'
                else:
                    clarified = 'harga_umum'
            else:
                clarified = f"{entity}_disambiguated"
            
            alternatives = [f"{entity}_option1", f"{entity}_option2"]
            
            return pb.DisambiguateEntityResponse(
                success=True,
                clarified_entity=clarified,
                entity_type="product" if 'baju' in entity else "pricing",
                disambiguation_confidence=0.8,
                alternative_interpretations=alternatives
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in DisambiguateEntity: {e}")
            return pb.DisambiguateEntityResponse(
                success=False,
                clarified_entity="disambiguation_failed",
                entity_type="unknown",
                disambiguation_confidence=0.0,
                alternative_interpretations=[]
            )
    
    # ========== STUB IMPLEMENTATIONS FOR REMAINING METHODS ==========
    # All methods have @telemetry decorator for consistency
    
    @telemetry
    async def PrioritizeImportantTurns(self, request: pb.PrioritizeImportantTurnsRequest, context) -> pb.PrioritizeImportantTurnsResponse:
        """Compress conversation by prioritizing important turns"""
        try:
            history = await self.history_manager.get_history(request.session_id, request.tenant_id)
            original_count = len(history)
            
            if original_count <= request.max_turns_to_keep:
                return pb.PrioritizeImportantTurnsResponse(
                    success=True,
                    message="No compression needed",
                    turns_compressed=0,
                    turns_retained=original_count
                )
            
            # Simple prioritization: keep recent turns and those with keywords
            important_keywords = ['beli', 'harga', 'problem', 'error', 'help', 'urgent']
            important_turns = []
            
            # Always keep last few turns
            important_turns.extend(history[:(request.max_turns_to_keep//2)])
            
            # Add turns with important keywords
            for turn in history[(request.max_turns_to_keep//2):]:
                if any(keyword in turn.lower() for keyword in important_keywords):
                    important_turns.append(turn)
            
            # Limit to max_turns_to_keep
            final_turns = important_turns[:request.max_turns_to_keep]
            compressed_count = original_count - len(final_turns)
            
            return pb.PrioritizeImportantTurnsResponse(
                success=True,
                message=f"Compressed {compressed_count} turns, retained {len(final_turns)} important turns",
                turns_compressed=compressed_count,
                turns_retained=len(final_turns)
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in PrioritizeImportantTurns: {e}")
            return pb.PrioritizeImportantTurnsResponse(
                success=False,
                message=f"Error prioritizing turns: {str(e)}",
                turns_compressed=0,
                turns_retained=0
            )
    
    @telemetry
    async def SummarizeContext(self, request: pb.SummarizeContextRequest, context) -> pb.SummarizeContextResponse:
        """Generate intelligent context summary"""
        try:
            history = await self.history_manager.get_history(request.session_id, request.tenant_id)
            
            if not history:
                return pb.SummarizeContextResponse(
                    success=True,
                    summary="No conversation history available",
                    key_entities=[],
                    key_intents="general_inquiry",
                    dominant_mood="neutral"
                )
            
            # Extract key information
            all_text = " ".join(history)
            product_analysis = await self.intelligence.detect_products_mentioned(all_text, request.tenant_id)
            mood, _, _ = await self.intelligence.detect_mood(all_text, request.tenant_id)
            
            # Generate summary based on type
            if request.summary_type == "brief":
                summary = f"Conversation with {len(history)} turns about {', '.join(product_analysis['categories'][:2])}"
            elif request.summary_type == "detailed":
                summary = f"Extended conversation covering {', '.join(product_analysis['categories'])}. User showed {mood} mood"
            else:
                summary = f"Standard summary: {len(history)} messages exchanged"
            
            return pb.SummarizeContextResponse(
                success=True,
                summary=summary,
                key_entities=product_analysis['products'][:5],
                key_intents=", ".join(product_analysis['categories']),
                dominant_mood=mood
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in SummarizeContext: {e}")
            return pb.SummarizeContextResponse(
                success=False,
                summary=f"Error generating summary: {str(e)}",
                key_entities=[],
                key_intents="unknown",
                dominant_mood="unknown"
            )
    
    @telemetry
    async def RecoverConversationFlow(self, request: pb.RecoverConversationFlowRequest, context) -> pb.RecoverConversationFlowResponse:
        """Recover from conversation flow disruptions"""
        try:
            # Recovery strategies based on disruption type
            if 'confusion' in request.disruption_point.lower():
                strategy = 'clarification_focused'
                transition = 'Mari saya jelaskan dengan lebih detail...'
                bridge = 'Untuk memastikan pemahaman yang tepat'
            elif 'topic_jump' in request.disruption_point.lower():
                strategy = 'topic_bridging'
                transition = 'Kembali ke topik sebelumnya...'
                bridge = 'Melanjutkan pembahasan mengenai'
            elif 'error' in request.disruption_point.lower():
                strategy = 'error_recovery'
                transition = 'Mohon maaf atas kendala teknis...'
                bridge = 'Mari kita coba pendekatan lain'
            else:
                strategy = 'general_recovery'
                transition = 'Mari kita lanjutkan dengan lebih baik...'
                bridge = 'Fokus pada kebutuhan utama Anda'
            
            return pb.RecoverConversationFlowResponse(
                success=True,
                recovery_strategy=strategy,
                suggested_transition=transition,
                context_bridge=bridge
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in RecoverConversationFlow: {e}")
            return pb.RecoverConversationFlowResponse(
                success=False,
                recovery_strategy="fallback",
                suggested_transition="Maaf, ada kendala sistem",
                context_bridge="Mari mulai dari awal"
            )
    
    @telemetry
    async def AdaptToneToUserMood(self, request: pb.AdaptToneToUserMoodRequest, context) -> pb.AdaptToneToUserMoodResponse:
        """Dynamically adapt response tone to user mood"""
        try:
            # Tone adaptation rules
            tone_map = {
                'happy': {
                    'tone': 'enthusiastic_supportive',
                    'justification': 'User is in positive mood, matching energy level',
                    'guidelines': ['Use positive language', 'Include emojis', 'Be encouraging']
                },
                'frustrated': {
                    'tone': 'calm_empathetic',
                    'justification': 'User needs reassurance and clear solutions',
                    'guidelines': ['Acknowledge frustration', 'Provide step-by-step help', 'Avoid complicated explanations']
                },
                'confused': {
                    'tone': 'patient_explanatory',
                    'justification': 'User needs clear, simple explanations',
                    'guidelines': ['Break down complex info', 'Use examples', 'Ask clarifying questions']
                }
            }
            
            tone_config = tone_map.get(request.current_mood, {
                'tone': 'professional_friendly',
                'justification': 'Default balanced approach',
                'guidelines': ['Maintain professional tone', 'Be helpful', 'Stay focused']
            })
            
            return pb.AdaptToneToUserMoodResponse(
                success=True,
                recommended_tone=tone_config['tone'],
                tone_justification=tone_config['justification'],
                tone_guidelines=tone_config['guidelines']
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in AdaptToneToUserMood: {e}")
            return pb.AdaptToneToUserMoodResponse(
                success=False,
                recommended_tone="neutral",
                tone_justification="Error in tone adaptation",
                tone_guidelines=["Use default tone"]
            )
    
    @telemetry
    async def TriggerResponseByPersona(self, request: pb.TriggerResponseByPersonaRequest, context) -> pb.TriggerResponseByPersonaResponse:
        """Generate brand-specific persona responses"""
        try:
            # Persona configurations
            persona_configs = {
                'friendly_expert': {
                    'style': 'knowledgeable_approachable',
                    'phrases': ['Saya senang membantu', 'Berdasarkan pengalaman', 'Mari kita lihat bersama'],
                    'template': 'Hai! {greeting} Sebagai ahli di bidang ini, {expertise} {solution}'
                },
                'professional_consultant': {
                    'style': 'formal_authoritative',
                    'phrases': ['Dengan senang hati', 'Berdasarkan analisis', 'Rekomendasi terbaik'],
                    'template': 'Selamat {time}. {analysis} Rekomendasi saya adalah {recommendation}'
                }
            }
            
            config = persona_configs.get(request.brand_persona, persona_configs['friendly_expert'])
            
            return pb.TriggerResponseByPersonaResponse(
                success=True,
                persona_response_style=config['style'],
                persona_phrases=config['phrases'],
                response_template=config['template']
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in TriggerResponseByPersona: {e}")
            return pb.TriggerResponseByPersonaResponse(
                success=False,
                persona_response_style="default",
                persona_phrases=["Terima kasih"],
                response_template="Default response template"
            )
    
    @telemetry
    async def SimulatedChainOfThought(self, request: pb.SimulatedChainOfThoughtRequest, context) -> pb.SimulatedChainOfThoughtResponse:
        """Show transparent reasoning process to user"""
        try:
            query = request.user_query.lower()
            reasoning_steps = []
            
            # Step 1: Query analysis
            reasoning_steps.append(f"ðŸ” Menganalisis pertanyaan: '{request.user_query}'")
            
            # Step 2: Intent detection
            if any(word in query for word in ['harga', 'berapa', 'biaya']):
                reasoning_steps.append("ðŸ’° Mendeteksi pertanyaan tentang harga/biaya")
                intent = "pricing_inquiry"
            elif any(word in query for word in ['cara', 'bagaimana', 'gimana']):
                reasoning_steps.append("â“ Mendeteksi pertanyaan tentang prosedur/cara")
                intent = "how_to_inquiry"
            else:
                reasoning_steps.append("â„¹ï¸ Pertanyaan umum terdeteksi")
                intent = "general_inquiry"
            
            reasoning_steps.append(f"ðŸŽ¯ Menentukan pendekatan terbaik untuk {intent}")
            reasoning_steps.append("âœï¸ Menyusun respons yang sesuai")
            
            final_conclusion = f"Berdasarkan analisis, ini adalah pertanyaan {intent}. Saya akan memberikan informasi yang relevan dan membantu."
            
            return pb.SimulatedChainOfThoughtResponse(
                success=True,
                reasoning_steps=reasoning_steps,
                final_conclusion=final_conclusion,
                confidence_score=0.85
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in SimulatedChainOfThought: {e}")
            return pb.SimulatedChainOfThoughtResponse(
                success=False,
                reasoning_steps=["Error in reasoning process"],
                final_conclusion="Unable to process reasoning",
                confidence_score=0.0
            )
    
    @telemetry
    async def AutoIntentCorrection(self, request: pb.AutoIntentCorrectionRequest, context) -> pb.AutoIntentCorrectionResponse:
        """Auto-correct misunderstood intents"""
        try:
            # Intent correction logic
            correction_map = {
                'pricing_inquiry': 'product_inquiry',
                'product_inquiry': 'pricing_inquiry',
                'general_inquiry': 'specific_inquiry',
                'support_request': 'information_request'
            }
            
            corrected = correction_map.get(request.misunderstood_intent, 'clarification_needed')
            
            clarification_questions = {
                'pricing_inquiry': 'Apakah Anda menanyakan tentang harga produk tertentu?',
                'product_inquiry': 'Apakah Anda ingin tahu detail produk atau informasi lainnya?',
                'general_inquiry': 'Bisakah Anda lebih spesifik tentang apa yang Anda butuhkan?'
            }
            
            clarification = clarification_questions.get(corrected, 'Mohon klarifikasi pertanyaan Anda.')
            apology = "Maaf jika saya kurang tepat memahami. Mari saya bantu dengan lebih baik."
            
            return pb.AutoIntentCorrectionResponse(
                success=True,
                corrected_intent=corrected,
                clarification_question=clarification,
                apology_message=apology
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in AutoIntentCorrection: {e}")
            return pb.AutoIntentCorrectionResponse(
                success=False,
                corrected_intent="correction_failed",
                clarification_question="Mohon ulangi pertanyaan Anda.",
                apology_message="Maaf, ada kendala sistem."
            )
    
    @telemetry
    async def DetectProductMentioned(self, request: pb.DetectProductMentionedRequest, context) -> pb.DetectProductMentionedResponse:
        """Detect products with tenant-specific patterns"""
        try:
            detection_result = await self.intelligence.detect_products_mentioned(
                request.conversation_turn, request.tenant_id
            )
            
            return pb.DetectProductMentionedResponse(
                success=True,
                products_mentioned=detection_result['products'],
                product_categories=detection_result['categories'],
                mention_confidence=detection_result['confidences']
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in DetectProductMentioned: {e}")
            return pb.DetectProductMentionedResponse(
                success=False,
                products_mentioned=[],
                product_categories=[],
                mention_confidence=[]
            )
    
    @telemetry
    async def DetectFrustrationEvents(self, request: pb.DetectFrustrationEventsRequest, context) -> pb.DetectFrustrationEventsResponse:
        """Detect user frustration and recommend actions"""
        try:
            history = await self.history_manager.get_history(request.session_id, request.tenant_id)
            current_message = history[0] if history else ""
            
            frustration_analysis = await self.intelligence.detect_frustration_level(
                current_message, history[1:], request.tenant_id
            )
            
            return pb.DetectFrustrationEventsResponse(
                success=True,
                frustration_indicators=frustration_analysis['indicators'],
                frustration_level=frustration_analysis['level'],
                recommended_actions=frustration_analysis['recommended_actions']
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in DetectFrustrationEvents: {e}")
            return pb.DetectFrustrationEventsResponse(
                success=False,
                frustration_indicators=[],
                frustration_level="unknown",
                recommended_actions=["default_support"]
            )
    
    @telemetry
    async def FindLeadSignals(self, request: pb.FindLeadSignalsRequest, context) -> pb.FindLeadSignalsResponse:
        """Detect buying intent and score leads"""
        try:
            history = await self.history_manager.get_history(request.session_id, request.tenant_id)
            all_text = " ".join(history).lower()
            
            # Buying signal detection
            buying_signals = []
            lead_score = 0.0
            
            # Strong buying signals
            strong_signals = ['mau beli', 'mau order', 'mau pesan', 'checkout', 'bayar sekarang']
            for signal in strong_signals:
                if signal in all_text:
                    buying_signals.append(signal)
                    lead_score += 0.3
            
            # Medium buying signals
            medium_signals = ['harga berapa', 'biaya', 'cara pembayaran', 'tersedia']
            for signal in medium_signals:
                if signal in all_text:
                    buying_signals.append(signal)
                    lead_score += 0.2
            
            # Determine lead stage
            if lead_score >= 0.7:
                lead_stage = 'ready_to_buy'
                follow_ups = ['Offer checkout assistance', 'Provide payment options', 'Close the deal']
            elif lead_score >= 0.4:
                lead_stage = 'considering'
                follow_ups = ['Share testimonials', 'Offer product demo', 'Provide detailed info']
            else:
                lead_stage = 'browsing'
                follow_ups = ['Build rapport', 'Educate about products', 'Stay helpful']
            
            return pb.FindLeadSignalsResponse(
                success=True,
                buying_signals=buying_signals[:5],
                lead_score=min(1.0, lead_score),
                lead_stage=lead_stage,
                recommended_follow_ups=follow_ups
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in FindLeadSignals: {e}")
            return pb.FindLeadSignalsResponse(
                success=False,
                buying_signals=[],
                lead_score=0.0,
                lead_stage="unknown",
                recommended_follow_ups=["default_follow_up"]
            )
    
    @telemetry
    async def CaptureFeedbackFromConversation(self, request: pb.CaptureFeedbackFromConversationRequest, context) -> pb.CaptureFeedbackFromConversationResponse:
        """Learn from conversation failures and patterns"""
        try:
            history = await self.history_manager.get_history(request.session_id, request.tenant_id)
            
            failure_patterns = []
            confusion_indicators = []
            improvements = []
            
            all_text = " ".join(history).lower()
            
            # Detect failure patterns
            if 'tidak mengerti' in all_text or 'bingung' in all_text:
                failure_patterns.append('unclear_communication')
                confusion_indicators.append('user_expressed_confusion')
                improvements.append('Improve clarity in explanations')
            
            if 'ulangi' in all_text or 'tidak jelas' in all_text:
                failure_patterns.append('repetitive_requests')
                confusion_indicators.append('user_asked_for_repetition')
                improvements.append('Provide information in different formats')
            
            # Calculate success score
            positive_indicators = ['terima kasih', 'bagus', 'membantu', 'jelas', 'paham']
            negative_indicators = ['tidak', 'bingung', 'susah', 'ribet', 'lambat']
            
            positive_count = sum(1 for indicator in positive_indicators if indicator in all_text)
            negative_count = sum(1 for indicator in negative_indicators if indicator in all_text)
            
            success_score = max(0.0, min(1.0, (positive_count - negative_count) / max(1, len(history))))
            
            return pb.CaptureFeedbackFromConversationResponse(
                success=True,
                failure_patterns=failure_patterns,
                confusion_indicators=confusion_indicators,
                improvement_opportunities=improvements,
                conversation_success_score=success_score
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in CaptureFeedbackFromConversation: {e}")
            return pb.CaptureFeedbackFromConversationResponse(
                success=False,
                failure_patterns=["analysis_error"],
                confusion_indicators=["system_error"],
                improvement_opportunities=["fix_analysis_system"],
                conversation_success_score=0.0
            )
    
    @telemetry
    async def ImproveResponseTemplateBasedOnFailure(self, request: pb.ImproveResponseTemplateBasedOnFailureRequest, context) -> pb.ImproveResponseTemplateBasedOnFailureResponse:
        """Auto-optimize response templates based on failure analysis"""
        try:
            # Template improvement rules
            improvement_rules = {
                'unclear_communication': {
                    'improved': 'Mari saya jelaskan dengan lebih detail dan contoh konkret...',
                    'reasons': ['Added detailed explanation', 'Included concrete examples', 'Simplified language'],
                    'update': 'Updated template to be more explanatory'
                },
                'repetitive_requests': {
                    'improved': 'Saya akan menyampaikan informasi dengan format yang berbeda...',
                    'reasons': ['Changed information format', 'Added visual structure', 'Provided alternatives'],
                    'update': 'Updated template to offer multiple formats'
                }
            }
            
            rule = improvement_rules.get(request.failure_pattern, {
                'improved': f"Improved version of: {request.original_response}",
                'reasons': ['General improvement applied'],
                'update': 'Applied standard improvements'
            })
            
            return pb.ImproveResponseTemplateBasedOnFailureResponse(
                success=True,
                improved_response=rule['improved'],
                improvement_reasons=rule['reasons'],
                template_update_applied=rule['update']
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in ImproveResponseTemplateBasedOnFailure: {e}")
            return pb.ImproveResponseTemplateBasedOnFailureResponse(
                success=False,
                improved_response="Error in improvement process",
                improvement_reasons=["system_error"],
                template_update_applied="no_update_applied"
            )
        """Detect products with tenant-specific patterns"""
        try:
            logger.info(f"ðŸ·ï¸ DetectProductMentioned: analyzing for tenant {request.tenant_id}")
            
            detection_result = await self.intelligence.detect_products_mentioned(
                request.conversation_turn, request.tenant_id
            )
            
            return pb.DetectProductMentionedResponse(
                success=True,
                products_mentioned=detection_result['products'],
                product_categories=detection_result['categories'],
                mention_confidence=detection_result['confidences']
            )
            
        except Exception as e:
            logger.error(f"âŒ Error in DetectProductMentioned: {e}")
            return pb.DetectProductMentionedResponse(
                success=False,
                products_mentioned=[],
                product_categories=[],
                mention_confidence=[]
            )
    
    @telemetry
    async def GetContext(self, request: pb.GetContextRequest, context) -> pb.GetContextResponse:
        """Get conversation context for session"""
        try:
            logger.info(f"ðŸ“¥ GetContext request: session={request.session_id}, tenant={request.tenant_id}")
            
            conv_context = await self.context_manager.get_context(
                request.session_id, request.tenant_id
            )
            
            if conv_context:
                return pb.GetContextResponse(
                    success=True,
                    context_data=f"Session: {request.session_id}, Turns: {conv_context.turn_count}"
                )
            else:
                return pb.GetContextResponse(
                    success=False,
                    context_data=f"No context found for session {request.session_id}"
                )
                
        except Exception as e:
            logger.error(f"âŒ Error in GetContext: {e}")
            return pb.GetContextResponse(
                success=False,
                context_data=f"Error retrieving context: {str(e)}"
            )
    
    # ========== SYSTEM METHODS ==========
    
    @telemetry
    async def HealthCheck(self, request: pb.HealthCheckRequest, context) -> pb.HealthCheckResponse:
        """Enhanced health check with metrics"""
        return pb.HealthCheckResponse(
            status="healthy",
            timestamp=int(time.time())
        )


# ========== HTTP METRICS ENDPOINT (for Prometheus integration) ==========

from aiohttp import web
import aiohttp

class MetricsHTTPServer:
    """HTTP server for exposing metrics endpoint"""
    
    def __init__(self, servicer: CustContextServicer, port: int = 8080):
        self.servicer = servicer
        self.port = port
        self.app = web.Application()
        self.app.router.add_get('/metrics', self.metrics_handler)
        self.app.router.add_get('/health', self.health_handler)
        self.runner = None
        self.site = None
    
    async def metrics_handler(self, request) -> web.Response:
        """HTTP endpoint for metrics (Enhanced Prometheus format with tenant labels)"""
        try:
            stats = await self.servicer.get_metrics_dict()
            
            # Convert to Prometheus format with enhanced labels
            prometheus_metrics = []
            prometheus_metrics.append("# HELP grpc_method_calls_total Total gRPC method calls")
            prometheus_metrics.append("# TYPE grpc_method_calls_total counter")
            
            for method, data in stats.items():
                for status, count in data["calls"].items():
                    prometheus_metrics.append(f'grpc_method_calls_total{{method="{method}",status="{status}",service="cust_context"}} {count}')
            
            prometheus_metrics.append("")
            prometheus_metrics.append("# HELP grpc_method_duration_seconds gRPC method duration")
            prometheus_metrics.append("# TYPE grpc_method_duration_seconds summary")
            
            for method, data in stats.items():
                prometheus_metrics.append(f'grpc_method_duration_seconds_avg{{method="{method}",service="cust_context"}} {data["avg_latency"]:.6f}')
                prometheus_metrics.append(f'grpc_method_duration_seconds_max{{method="{method}",service="cust_context"}} {data["max_latency"]:.6f}')
                prometheus_metrics.append(f'grpc_method_duration_seconds_min{{method="{method}",service="cust_context"}} {data["min_latency"]:.6f}')
                prometheus_metrics.append(f'grpc_method_duration_seconds{{method="{method}",service="cust_context",quantile="0.95"}} {data["p95_latency"]:.6f}')
            
            prometheus_metrics.append("")
            return web.Response(text="\n".join(prometheus_metrics), content_type="text/plain")
            
        except Exception as e:
            logger.error(f"Metrics endpoint error: {e}")
            return web.Response(text="Error generating metrics", status=500)
    
    async def health_handler(self, request) -> web.Response:
        """HTTP health check endpoint"""
        return web.json_response({"status": "healthy", "timestamp": int(time.time())})
    
    async def start(self):
        """Start HTTP metrics server"""
        try:
            self.runner = web.AppRunner(self.app)
            await self.runner.setup()
            self.site = web.TCPSite(self.runner, '0.0.0.0', self.port)
            await self.site.start()
            logger.info(f"ðŸ“Š HTTP metrics server started on port {self.port}")
        except Exception as e:
            logger.error(f"Failed to start HTTP metrics server: {e}")
    
    async def stop(self):
        """Stop HTTP metrics server"""
        if self.site:
            await self.site.stop()
        if self.runner:
            await self.runner.cleanup()
        logger.info("ðŸ“Š HTTP metrics server stopped")


class HealthServicer(health_pb2_grpc.HealthServicer):
    """Standard gRPC health check servicer"""
    async def Check(self, request, context):
        return health_pb2.HealthCheckResponse(
            status=health_pb2.HealthCheckResponse.SERVING
        )


async def serve():
    """Start the production-optimized Level 13 Customer Context gRPC Server"""
    # Initialize server
    server = aio.server()
    
    # Create servicer
    servicer = CustContextServicer()
    
    # CRITICAL: Initialize all managers BEFORE accepting requests
    logger.info("ðŸ”§ Initializing servicer managers...")
    await servicer.initialize()
    
    # Add servicers to gRPC server
    pb_grpc.add_CustContextServiceServicer_to_server(servicer, server)
    health_pb2_grpc.add_HealthServicer_to_server(HealthServicer(), server)
    
    # Configure gRPC server
    listen_addr = f"[::]:{settings.GRPC_PORT}"
    server.add_insecure_port(listen_addr)
    
    # Start HTTP metrics server
    metrics_server = MetricsHTTPServer(servicer, port=8080)
    await metrics_server.start()
    
    # Enhanced graceful shutdown handler with proper order
    async def shutdown_handler():
        logger.info("ðŸ›‘ Shutting down Level 13 Customer Context Service...")
        
        # Step 1: Stop HTTP metrics server first
        await metrics_server.stop()
        
        # Step 2: Stop accepting new gRPC requests 
        server.stop(grace=10.0)
        
        # Step 3: Cleanup service resources after requests are drained
        await servicer.cleanup()
        
        logger.info("âœ… Graceful shutdown completed")
    
    # Register signal handlers
    loop = asyncio.get_event_loop()
    for sig in (signal.SIGTERM, signal.SIGINT):
        loop.add_signal_handler(sig, lambda: asyncio.create_task(shutdown_handler()))
    
    # Start gRPC server
    logger.info("ðŸš€ Starting Level 13 'DEWA' Customer Context Service...")
    await server.start()
    logger.info(f"ðŸŽ¯ Level 13 gRPC Service listening on {listen_addr}")
    logger.info(f"ðŸ“Š HTTP Metrics endpoint: http://localhost:8080/metrics")
    logger.info(f"â¤ï¸ HTTP Health endpoint: http://localhost:8080/health")
    logger.info("âœ¨ Production-Grade Features ACTIVE:")
    logger.info("  ðŸ”§ Tenant-specific configurations with Redis caching & thread-safe access")
    logger.info("  ðŸ’¾ Redis-backed conversation history with bulk operations & fallback")
    logger.info("  ðŸ“Š Comprehensive telemetry with error classification & P95 latencies")
    logger.info("  ðŸ—ï¸ Generic tenant handling (zero hard-coding)")
    logger.info("  ðŸ›¡ï¸ Connection cleanup, graceful shutdown & resource management")
    logger.info("  ðŸŒ HTTP metrics endpoint for Prometheus integration")
    logger.info("  âš¡ All 22 methods with consistent telemetry coverage")
    
    try:
        await server.wait_for_termination()
    except KeyboardInterrupt:
        logger.info("ðŸ›‘ Server interrupted by user")
        await shutdown_handler()
    finally:
        logger.info("âœ… Level 13 Customer Context Service stopped gracefully")


if __name__ == "__main__":
    # Set environment for optimal performance
    os.environ.setdefault('PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION', 'python')
    
    # Run the production-optimized Level 13 service
    asyncio.run(serve())